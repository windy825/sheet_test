# app_improved.py â€” ì™„ì „ ê°œì„  ë²„ì „
# ------------------------------------------------------------------
# ê°œì„ ì‚¬í•­:
# - ëª¨ë“  ë°ì´í„° êµ¬ì¡° ë¶ˆì¼ì¹˜ í•´ê²°
# - ì•ˆì „í•œ ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…
# - ì„±ëŠ¥ ìµœì í™”ëœ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
# - í–¥ìƒëœ ì‚¬ìš©ì ê²½í—˜
# - ë©”ëª¨ë¦¬ ìµœì í™”
# ------------------------------------------------------------------

import io
import re
import math
import logging
import itertools
import typing as t
from datetime import datetime, timedelta
import pandas as pd
import streamlit as st

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Streamlit ì„¤ì •
st.set_page_config(
    page_title="ì„ ìˆ˜/ì„ ê¸‰ê¸ˆ ê³„ì•½ë³„ ëŒ€ì‹œë³´ë“œ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“Š ì„ ìˆ˜/ì„ ê¸‰ê¸ˆ ê³„ì•½ë³„ ëŒ€ì‹œë³´ë“œ â€” ì™„ì „ ê°œì„  ë²„ì „")
st.caption("ì—‘ì…€ ì—…ë¡œë“œ â†’ í‘œì¤€í™” â†’ ì§‘ê³„ â†’ ìƒì„¸/ì°¨íŠ¸ â†’ êµì°¨ê²€ì¦ ìë™ ë§¤ì¹­")

# ============== ìƒìˆ˜ ë° ìœ í‹¸ë¦¬í‹° ==============
_non_digit = re.compile(r"[^0-9\-\.]+")

# í‘œì¤€ ì»¬ëŸ¼ ì •ì˜
STANDARD_COLS = [
    "contract_id", "direction", "amount", "date", "party",
    "owner", "status", "note", "overdue_flag"
]

# ì»¬ëŸ¼ ë§¤ì¹­ í›„ë³´ë“¤
COLUMN_CANDIDATES = {
    "contract": ["ê³„ì•½ë²ˆí˜¸", "ê¸ˆí˜•ë§ˆìŠ¤í„°", "í”„ë¡œì íŠ¸", "í”„ë¡œì íŠ¸ì½”ë“œ", "PJT", "PJTì½”ë“œ", "ê³ ìœ ë²ˆí˜¸", "ê³„ì•½ì½”ë“œ", "ê³„ì•½id", "ê³„ì•½ID"],
    "amount": ["ê¸ˆì•¡", "ì„ ìˆ˜ê¸ˆ", "ì„ ê¸‰ê¸ˆ", "ì„ ìˆ˜ê¸ˆê¸ˆì•¡", "ì„ ê¸‰ê¸ˆê¸ˆì•¡", "í•©ê³„", "ì”ì•¡", "amount"],
    "date": ["ì¼ì", "ì²­êµ¬ì¼", "ì§€ê¸‰ì¼", "ë‚©ê¸°ì¼", "ìš”ì²­ì¼", "ë“±ë¡ì¼", "ê¸°ì¤€ì¼", "date"],
    "party": ["ì—…ì²´ëª…", "ê±°ë˜ì²˜", "ê³ ê°ì‚¬", "ê³ ê°ëª…", "ìƒëŒ€ë°©", "íšŒì‚¬", "vendor", "customer", "ì—…ì²´"],
    "owner": ["ë‹´ë‹¹ì", "ë‹´ë‹¹", "ë‹´ë‹¹ìëª…", "PM", "ë‹´ë‹¹ë¶€ì„œ", "owner"],
    "status": ["ì§„í–‰í˜„í™©", "ì •ì‚°ì—¬ë¶€", "ìƒíƒœ", "status"],
    "note": ["ë¹„ê³ ", "ë©”ëª¨", "íŠ¹ì´ì‚¬í•­", "ì½”ë©˜íŠ¸", "note", "ì„¤ëª…"],
    "overdue": ["ê¸°í•œê²½ê³¼", "ì—°ì²´", "overdue", "ê²½ê³¼"]
}

def to_float(x: t.Any) -> float:
    """ì•ˆì „í•œ ìˆ«ì ë³€í™˜"""
    try:
        if x is None or (isinstance(x, float) and math.isnan(x)):
            return 0.0
        if isinstance(x, (int, float)):
            return float(x)
        
        s = str(x).strip()
        if s == "" or s.lower() in {"nan", "none", "null"}:
            return 0.0
        
        # ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ì ì œê±°
        s = _non_digit.sub("", s)
        if s in {"", "-", "."}:
            return 0.0
        
        return float(s)
    except Exception as e:
        logger.warning(f"ìˆ«ì ë³€í™˜ ì‹¤íŒ¨: {x} -> {e}")
        return 0.0

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """ì»¬ëŸ¼ëª… ì •ê·œí™”"""
    if df.empty:
        return df
    
    df = df.copy()
    new_cols, seen = [], set()
    
    for c in df.columns:
        nc = str(c).strip()
        nc = re.sub(r"\s+", " ", nc)
        
        # ì¤‘ë³µ ì»¬ëŸ¼ëª… ì²˜ë¦¬
        if nc in seen:
            k, base = 2, nc
            while nc in seen:
                nc = f"{base}_{k}"
                k += 1
        
        seen.add(nc)
        new_cols.append(nc)
    
    df.columns = new_cols
    return df

def find_column_match(df: pd.DataFrame, candidates: t.List[str]) -> t.Optional[str]:
    """ì»¬ëŸ¼ ë§¤ì¹­ ë¡œì§ ê°œì„ """
    if df.empty:
        return None
    
    cols = list(df.columns)
    lower_map = {c.lower(): c for c in cols}
    
    # ì •í™•í•œ ë§¤ì¹˜ ìš°ì„ 
    for cand in candidates:
        if cand in df.columns:
            return cand
        if cand.lower() in lower_map:
            return lower_map[cand.lower()]
    
    # ë¶€ë¶„ ë§¤ì¹˜
    for cand in candidates:
        pattern = re.compile(re.escape(cand), re.IGNORECASE)
        for c in cols:
            if pattern.search(str(c)):
                return c
    
    return None

def read_sheet_safely(excel_file: pd.ExcelFile, keywords: t.List[str]) -> pd.DataFrame:
    """ì‹œíŠ¸ ì½ê¸° ì•ˆì „ ì²˜ë¦¬"""
    try:
        def normalize_name(s: str) -> str:
            return re.sub(r"\s+", "", s.lower())
        
        target_sheet = None
        for sheet_name in excel_file.sheet_names:
            normalized = normalize_name(sheet_name)
            if any(normalize_name(k) in normalized for k in keywords):
                target_sheet = sheet_name
                break
        
        if target_sheet is None:
            logger.warning(f"í‚¤ì›Œë“œ {keywords}ì— í•´ë‹¹í•˜ëŠ” ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        df = pd.read_excel(excel_file, sheet_name=target_sheet, dtype=str)
        return normalize_columns(df)
        
    except Exception as e:
        logger.error(f"ì‹œíŠ¸ ì½ê¸° ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

def standardize_data(df: pd.DataFrame, direction: str) -> pd.DataFrame:
    """ë°ì´í„° í‘œì¤€í™” ê°œì„ """
    if df is None or df.empty:
        return pd.DataFrame(columns=STANDARD_COLS)
    
    try:
        df = normalize_columns(df)
        
        # ì»¬ëŸ¼ ë§¤ì¹­
        col_mapping = {}
        for col_type, candidates in COLUMN_CANDIDATES.items():
            matched_col = find_column_match(df, candidates)
            col_mapping[col_type] = matched_col
        
        # ê³„ì•½IDê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©
        if col_mapping["contract"] is None and not df.empty:
            col_mapping["contract"] = df.columns[0]
            logger.info(f"ê³„ì•½ID ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ '{df.columns[0]}'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # í‘œì¤€ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        result = pd.DataFrame()
        
        result["contract_id"] = (
            df[col_mapping["contract"]].astype(str).str.strip()
            if col_mapping["contract"] else "(ë¯¸ì§€ì •)"
        )
        result["direction"] = direction
        result["amount"] = (
            df[col_mapping["amount"]].apply(to_float)
            if col_mapping["amount"] else 0.0
        )
        result["date"] = (
            pd.to_datetime(df[col_mapping["date"]], errors="coerce")
            if col_mapping["date"] else pd.NaT
        )
        result["party"] = (
            df[col_mapping["party"]].astype(str).str.strip()
            if col_mapping["party"] else ""
        )
        result["owner"] = (
            df[col_mapping["owner"]].astype(str).str.strip()
            if col_mapping["owner"] else ""
        )
        result["status"] = (
            df[col_mapping["status"]].astype(str).str.strip()
            if col_mapping["status"] else ""
        )
        result["note"] = (
            df[col_mapping["note"]].astype(str).str.strip()
            if col_mapping["note"] else ""
        )
        
        # ì—°ì²´ í”Œë˜ê·¸ ì²˜ë¦¬
        if col_mapping["overdue"]:
            overdue_data = df[col_mapping["overdue"]].astype(str).str.strip().str.lower()
            result["overdue_flag"] = (
                overdue_data.isin(["y", "yes", "true", "1", "o"]) |
                overdue_data.str.contains("ê²½ê³¼|ì—°ì²´|over", na=False)
            )
        else:
            result["overdue_flag"] = False
        
        # ìœ íš¨í•œ ë°ì´í„°ë§Œ í•„í„°ë§
        result = result[
            (result["amount"] != 0) &
            (result["contract_id"].str.strip() != "") &
            (result["contract_id"] != "nan")
        ]
        
        logger.info(f"{direction} ë°ì´í„° {len(result)}ê±´ í‘œì¤€í™” ì™„ë£Œ")
        return result[STANDARD_COLS]
        
    except Exception as e:
        logger.error(f"ë°ì´í„° í‘œì¤€í™” ì˜¤ë¥˜: {e}")
        return pd.DataFrame(columns=STANDARD_COLS)

def create_aggregation_table(base_df: pd.DataFrame) -> pd.DataFrame:
    """ì§‘ê³„ í…Œì´ë¸” ìƒì„± ê°œì„  - ë””ë²„ê¹… ê°•í™”"""
    if base_df.empty:
        logger.warning("ì§‘ê³„ í…Œì´ë¸”: ì…ë ¥ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
        return pd.DataFrame(columns=[
            "ê³„ì•½ID", "ì„ ìˆ˜ê¸ˆ_í•©ê³„", "ì„ ê¸‰ê¸ˆ_í•©ê³„", "Gap(ì„ ìˆ˜-ì„ ê¸‰)",
            "ë‹´ë‹¹ì", "ì£¼ìš”ê±°ë˜ì²˜", "ìµœê·¼ì¼ì", "ê±´ìˆ˜"
        ])
    
    try:
        logger.info(f"ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì‹œì‘: {len(base_df)}ê±´ì˜ ë°ì´í„°")
        
        # ê³„ì•½IDë³„ ì§‘ê³„
        all_contracts = base_df["contract_id"].dropna().unique()
        logger.info(f"ì´ ê³„ì•½ ìˆ˜: {len(all_contracts)}ê°œ")
        
        result_rows = []
        
        for idx, contract in enumerate(all_contracts):
            if pd.isna(contract) or str(contract).strip() == "" or str(contract) == "nan":
                logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ê³„ì•½ID ê±´ë„ˆëœ€: {contract}")
                continue
                
            contract_data = base_df[base_df["contract_id"] == contract]
            
            if contract_data.empty:
                logger.warning(f"ê³„ì•½ {contract}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŒ")
                continue
            
            # ê¸ˆì•¡ ì§‘ê³„
            receipts_data = contract_data[contract_data["direction"] == "ì„ ìˆ˜ê¸ˆ"]
            advances_data = contract_data[contract_data["direction"] == "ì„ ê¸‰ê¸ˆ"]
            
            ì„ ìˆ˜ê¸ˆ_í•©ê³„ = receipts_data["amount"].sum() if not receipts_data.empty else 0.0
            ì„ ê¸‰ê¸ˆ_í•©ê³„ = advances_data["amount"].sum() if not advances_data.empty else 0.0
            gap = ì„ ìˆ˜ê¸ˆ_í•©ê³„ - ì„ ê¸‰ê¸ˆ_í•©ê³„
            
            # ë©”íƒ€ ì •ë³´ ì¶”ì¶œ - ê°œì„ ëœ ë¡œì§
            ë‹´ë‹¹ì_list = contract_data["owner"].dropna().astype(str).tolist()
            ë‹´ë‹¹ì_list = [owner for owner in ë‹´ë‹¹ì_list if owner not in ['', 'nan', 'None']]
            
            if ë‹´ë‹¹ì_list:
                # ê°€ì¥ ë¹ˆë„ê°€ ë†’ì€ ë‹´ë‹¹ì
                ë‹´ë‹¹ì = max(set(ë‹´ë‹¹ì_list), key=ë‹´ë‹¹ì_list.count)
            else:
                ë‹´ë‹¹ì = ""
            
            ê±°ë˜ì²˜_list = contract_data["party"].dropna().astype(str).tolist()
            ê±°ë˜ì²˜_list = [party for party in ê±°ë˜ì²˜_list if party not in ['', 'nan', 'None']]
            
            if ê±°ë˜ì²˜_list:
                # ê°€ì¥ ë¹ˆë„ê°€ ë†’ì€ ê±°ë˜ì²˜
                ì£¼ìš”ê±°ë˜ì²˜ = max(set(ê±°ë˜ì²˜_list), key=ê±°ë˜ì²˜_list.count)
            else:
                ì£¼ìš”ê±°ë˜ì²˜ = ""
            
            ìµœê·¼ì¼ì = contract_data["date"].max() if contract_data["date"].notna().any() else pd.NaT
            ê±´ìˆ˜ = len(contract_data)
            
            row_data = {
                "ê³„ì•½ID": str(contract),
                "ì„ ìˆ˜ê¸ˆ_í•©ê³„": float(ì„ ìˆ˜ê¸ˆ_í•©ê³„),
                "ì„ ê¸‰ê¸ˆ_í•©ê³„": float(ì„ ê¸‰ê¸ˆ_í•©ê³„),
                "Gap(ì„ ìˆ˜-ì„ ê¸‰)": float(gap),
                "ë‹´ë‹¹ì": str(ë‹´ë‹¹ì) if ë‹´ë‹¹ì else "",
                "ì£¼ìš”ê±°ë˜ì²˜": str(ì£¼ìš”ê±°ë˜ì²˜) if ì£¼ìš”ê±°ë˜ì²˜ else "",
                "ìµœê·¼ì¼ì": ìµœê·¼ì¼ì,
                "ê±´ìˆ˜": int(ê±´ìˆ˜)
            }
            
            result_rows.append(row_data)
            
            # ì§„í–‰ ìƒí™© ë¡œê¹… (100ê°œë§ˆë‹¤)
            if (idx + 1) % 100 == 0:
                logger.info(f"ì§‘ê³„ ì§„í–‰: {idx + 1}/{len(all_contracts)} ì™„ë£Œ")
        
        result_df = pd.DataFrame(result_rows)
        
        # ê²°ê³¼ ê²€ì¦
        if result_df.empty:
            logger.error("ì§‘ê³„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
        else:
            logger.info(f"ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {len(result_df)}ê°œ ê³„ì•½")
            logger.info(f"ì»¬ëŸ¼: {list(result_df.columns)}")
            
            # ê° ì»¬ëŸ¼ì˜ ë°ì´í„° í’ˆì§ˆ ì²´í¬
            for col in result_df.columns:
                non_null_count = result_df[col].notna().sum()
                logger.info(f"ì»¬ëŸ¼ '{col}': {non_null_count}/{len(result_df)} ê°œ ìœ íš¨ ë°ì´í„°")
        
        return result_df
        
    except Exception as e:
        logger.error(f"ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ ì‹œì ì˜ ë°ì´í„° í˜•íƒœ: {base_df.dtypes}")
        return pd.DataFrame(columns=[
            "ê³„ì•½ID", "ì„ ìˆ˜ê¸ˆ_í•©ê³„", "ì„ ê¸‰ê¸ˆ_í•©ê³„", "Gap(ì„ ìˆ˜-ì„ ê¸‰)",
            "ë‹´ë‹¹ì", "ì£¼ìš”ê±°ë˜ì²˜", "ìµœê·¼ì¼ì", "ê±´ìˆ˜"
        ])

# ============== ìºì‹œëœ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ==============
@st.cache_data(show_spinner=True, ttl=3600)
def load_excel_data(file_bytes: bytes):
    """ì—‘ì…€ ë°ì´í„° ë¡œë“œ (ìºì‹œ ì ìš©)"""
    try:
        excel_file = pd.ExcelFile(io.BytesIO(file_bytes), engine="openpyxl")
        
        # ì‹œíŠ¸ ì½ê¸°
        receipts_raw = read_sheet_safely(excel_file, ["ì„ ìˆ˜ê¸ˆ"])
        advances_raw = read_sheet_safely(excel_file, ["ì„ ê¸‰ê¸ˆ"])
        
        # ë°ì´í„° í‘œì¤€í™”
        receipts_std = standardize_data(receipts_raw, "ì„ ìˆ˜ê¸ˆ")
        advances_std = standardize_data(advances_raw, "ì„ ê¸‰ê¸ˆ")
        
        # í†µí•© ë°ì´í„°
        base_data = pd.concat([receipts_std, advances_std], ignore_index=True)
        
        # ì§‘ê³„ í…Œì´ë¸”
        aggregation_table = create_aggregation_table(base_data)
        
        # ë°ì´í„° ê²€ì¦
        validation_info = {
            "ì„ ìˆ˜ê¸ˆ_ì›ë³¸_í–‰ìˆ˜": len(receipts_raw),
            "ì„ ê¸‰ê¸ˆ_ì›ë³¸_í–‰ìˆ˜": len(advances_raw),
            "ì„ ìˆ˜ê¸ˆ_í‘œì¤€í™”_í–‰ìˆ˜": len(receipts_std),
            "ì„ ê¸‰ê¸ˆ_í‘œì¤€í™”_í–‰ìˆ˜": len(advances_std),
            "ì´_ê³„ì•½ìˆ˜": len(aggregation_table),
            "ì‹œíŠ¸_ëª©ë¡": excel_file.sheet_names
        }
        
        return base_data, aggregation_table, receipts_std, advances_std, validation_info
        
    except Exception as e:
        logger.error(f"ì—‘ì…€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        empty_df = pd.DataFrame(columns=STANDARD_COLS)
        empty_agg = pd.DataFrame(columns=[
            "ê³„ì•½ID", "ì„ ìˆ˜ê¸ˆ_í•©ê³„", "ì„ ê¸‰ê¸ˆ_í•©ê³„", "Gap(ì„ ìˆ˜-ì„ ê¸‰)",
            "ë‹´ë‹¹ì", "ì£¼ìš”ê±°ë˜ì²˜", "ìµœê·¼ì¼ì", "ê±´ìˆ˜"
        ])
        error_info = {"error": str(e)}
        return empty_df, empty_agg, empty_df, empty_df, error_info

def apply_filters(view_df: pd.DataFrame, query_text: str, owner_filter: str) -> pd.DataFrame:
    """í•„í„°ë§ ë¡œì§ ê°œì„  - ë””ë²„ê¹… ê°•í™”"""
    if view_df.empty:
        logger.warning("í•„í„°ë§: ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆìŒ")
        return view_df
    
    try:
        filtered_df = view_df.copy()
        initial_count = len(filtered_df)
        
        logger.info(f"í•„í„°ë§ ì‹œì‘: {initial_count}ê±´ì˜ ë°ì´í„°")
        logger.info(f"ê²€ìƒ‰ì–´: '{query_text}', ë‹´ë‹¹ì í•„í„°: '{owner_filter}'")
        logger.info(f"ì»¬ëŸ¼ ëª©ë¡: {list(filtered_df.columns)}")
        
        # ê²€ìƒ‰ í•„í„° ì ìš©
        if query_text and query_text.strip():
            query_text = query_text.strip()
            logger.info(f"ê²€ìƒ‰ í•„í„° ì ìš©: '{query_text}'")
            
            # ê° ì»¬ëŸ¼ë³„ë¡œ ê°œë³„ í™•ì¸
            contract_mask = pd.Series([False] * len(filtered_df))
            party_mask = pd.Series([False] * len(filtered_df))
            owner_mask = pd.Series([False] * len(filtered_df))
            
            if "ê³„ì•½ID" in filtered_df.columns:
                contract_mask = filtered_df["ê³„ì•½ID"].astype(str).str.contains(query_text, case=False, na=False, regex=False)
                logger.info(f"ê³„ì•½ID ë§¤ì¹˜: {contract_mask.sum()}ê±´")
            
            if "ì£¼ìš”ê±°ë˜ì²˜" in filtered_df.columns:
                party_mask = filtered_df["ì£¼ìš”ê±°ë˜ì²˜"].astype(str).str.contains(query_text, case=False, na=False, regex=False)
                logger.info(f"ì£¼ìš”ê±°ë˜ì²˜ ë§¤ì¹˜: {party_mask.sum()}ê±´")
            
            if "ë‹´ë‹¹ì" in filtered_df.columns:
                owner_mask = filtered_df["ë‹´ë‹¹ì"].astype(str).str.contains(query_text, case=False, na=False, regex=False)
                logger.info(f"ë‹´ë‹¹ì ë§¤ì¹˜: {owner_mask.sum()}ê±´")
            
            # í†µí•© ë§ˆìŠ¤í¬
            search_mask = contract_mask | party_mask | owner_mask
            logger.info(f"í†µí•© ê²€ìƒ‰ ê²°ê³¼: {search_mask.sum()}ê±´")
            
            filtered_df = filtered_df[search_mask]
            logger.info(f"ê²€ìƒ‰ í›„ ë°ì´í„°: {len(filtered_df)}ê±´")
        
        # ë‹´ë‹¹ì í•„í„° ì ìš©
        if owner_filter and owner_filter.strip():
            logger.info(f"ë‹´ë‹¹ì í•„í„° ì ìš©: '{owner_filter}'")
            owners = [o.strip() for o in owner_filter.split(',') if o.strip()]
            logger.info(f"ë‹´ë‹¹ì ëª©ë¡: {owners}")
            
            if owners and "ë‹´ë‹¹ì" in filtered_df.columns:
                # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë¶€ë¶„ ë§¤ì¹˜
                owner_mask = pd.Series([False] * len(filtered_df))
                for owner in owners:
                    mask = filtered_df["ë‹´ë‹¹ì"].astype(str).str.contains(owner, case=False, na=False, regex=False)
                    owner_mask = owner_mask | mask
                    logger.info(f"'{owner}' ë§¤ì¹˜: {mask.sum()}ê±´")
                
                filtered_df = filtered_df[owner_mask]
                logger.info(f"ë‹´ë‹¹ì í•„í„° í›„ ë°ì´í„°: {len(filtered_df)}ê±´")
        
        logger.info(f"ìµœì¢… í•„í„°ë§ ê²°ê³¼: {len(filtered_df)}ê±´ (ì›ë³¸ {initial_count}ê±´)")
        
        return filtered_df
        
    except Exception as e:
        logger.error(f"í•„í„°ë§ ì˜¤ë¥˜: {e}")
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ ì‹œì  - ê²€ìƒ‰ì–´: '{query_text}', ë‹´ë‹¹ì: '{owner_filter}'")
        return view_df

def safe_sort(df: pd.DataFrame, sort_column: str) -> pd.DataFrame:
    """ì•ˆì „í•œ ì •ë ¬ í•¨ìˆ˜"""
    if df.empty:
        return df
    
    try:
        if sort_column not in df.columns:
            st.warning(f"ì •ë ¬ ì»¬ëŸ¼ '{sort_column}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return df
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ì€ ë‚´ë¦¼ì°¨ìˆœ, ë¬¸ìí˜•ì€ ì˜¤ë¦„ì°¨ìˆœ
        if pd.api.types.is_numeric_dtype(df[sort_column]):
            return df.sort_values(by=sort_column, ascending=False)
        else:
            return df.sort_values(by=sort_column, ascending=True)
            
    except Exception as e:
        logger.error(f"ì •ë ¬ ì˜¤ë¥˜: {e}")
        return df

# ============== ê°œì„ ëœ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ==============
def simple_tokenize(text: str) -> set:
    """ê°„ë‹¨í•œ í† í°í™”"""
    if not text or pd.isna(text):
        return set()
    
    text = str(text)
    # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
    text = re.sub(r'[^0-9A-Za-zê°€-í£\-_/]+', ' ', text)
    tokens = [t for t in text.split() if len(t) >= 2]
    return set(tokens)

def calculate_match_score(receipt_row: pd.Series, advance_row: pd.Series,
                          config: dict) -> float:
    """ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
    score = 0.0
    
    try:
        ramt = float(receipt_row.get('amount', 0) or 0)
        aamt = float(advance_row.get('amount', 0) or 0)
        rdate = receipt_row.get('date', pd.NaT)
        adate = advance_row.get('date', pd.NaT)
        
        # ê¸ˆì•¡ ì ìˆ˜ (40%)
        if config.get('use_amount', True) and ramt > 0:
            amt_diff = abs(ramt - aamt)
            tol_abs = config.get('amount_tol', 0)
            tol_pct = config.get('amount_tol_pct', 1) / 100.0
            tolerance = max(tol_abs, ramt * tol_pct)
            
            if amt_diff <= tolerance:
                score += max(0.0, 1.0 - (amt_diff / (ramt + 1e-9))) * 0.4
        
        # ë‚ ì§œ ì ìˆ˜ (30%)
        if config.get('use_date', True) and pd.notna(rdate) and pd.notna(adate):
            date_diff = abs((rdate - adate).days)
            date_window = config.get('date_window', 30)
            if date_diff <= date_window:
                score += max(0.0, 1.0 - (date_diff / (date_window + 1))) * 0.3
        
        # ê³„ì•½ID ì ìˆ˜ (20%)
        if config.get('use_contract_soft', True):
            r_contract = str(receipt_row.get('contract_id', '')).strip()
            a_contract = str(advance_row.get('contract_id', '')).strip()
            if (r_contract == a_contract and r_contract != '' and
                r_contract not in ['nan', 'None', '(ë¯¸ì§€ì •)']):
                score += 0.2
        
        # ê±°ë˜ì²˜/í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ì ìˆ˜ (10%)
        if config.get('use_party_soft', True):
            r_tokens = simple_tokenize(
                f"{receipt_row.get('party', '')} {receipt_row.get('note', '')} "
                f"{receipt_row.get('status', '')}"
            )
            a_tokens = simple_tokenize(
                f"{advance_row.get('party', '')} {advance_row.get('note', '')} "
                f"{advance_row.get('status', '')}"
            )
            
            if r_tokens and a_tokens:
                intersection = len(r_tokens.intersection(a_tokens))
                union = len(r_tokens.union(a_tokens))
                if union > 0:
                    similarity = intersection / union
                    score += similarity * 0.1
        
        return score
        
    except Exception as e:
        logger.error(f"ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0

@st.cache_data(show_spinner=True)
def compute_matches_optimized(receipts_df: pd.DataFrame, advances_df: pd.DataFrame,
                              config: dict) -> pd.DataFrame:
    """ìµœì í™”ëœ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜"""
    if receipts_df.empty or advances_df.empty:
        return pd.DataFrame(columns=['rid', 'aids', 'sum_adv', 'gap', 'score', 'match_type'])
    
    try:
        rec = receipts_df.reset_index(drop=True).copy()
        adv = advances_df.reset_index(drop=True).copy()
        
        rec['rid'] = rec.index
        adv['aid'] = adv.index
        
        matches = []
        used_advances = set()  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
        
        # ê° ì„ ìˆ˜ê¸ˆì— ëŒ€í•´ ë§¤ì¹­ ì‹œë„
        for _, receipt in rec.iterrows():
            ramt = float(receipt.get('amount', 0) or 0)
            if ramt <= 0:
                continue
            
            # ì‚¬ìš©ë˜ì§€ ì•Šì€ ì„ ê¸‰ê¸ˆë§Œ ê³ ë ¤
            available_advances = adv[~adv['aid'].isin(used_advances)].copy()
            if available_advances.empty:
                continue
            
            # í›„ë³´ í•„í„°ë§
            candidates = filter_candidates(receipt, available_advances, config)
            if candidates.empty:
                continue
            
            # 1:1 ë§¤ì¹­ ì‹œë„
            best_single = find_best_single_match(receipt, candidates, config)
            
            # 1:N ë§¤ì¹­ ì‹œë„ (ì¡°ê±´: 1:1ì´ ì—†ê±°ë‚˜ ì •í™•ë„ê°€ ë‚®ì€ ê²½ìš°)
            best_combo = None
            if (best_single is None or best_single['score'] < 0.7 or
                abs(best_single['gap']) > config.get('amount_tol', 0)):
                
                max_combo = min(config.get('max_combo', 3), len(candidates))
                if max_combo > 1:
                    best_combo = find_best_combo_match(receipt, candidates, config, max_combo)
            
            # ìµœì  ë§¤ì¹­ ì„ íƒ
            final_match = None
            if best_combo and (best_single is None or best_combo['score'] > best_single['score']):
                final_match = best_combo
            elif best_single:
                final_match = best_single
            
            if final_match:
                # ì‚¬ìš©ëœ ì„ ê¸‰ê¸ˆ ê¸°ë¡
                used_advances.update(final_match['aids'])
                matches.append(final_match)
        
        result_df = pd.DataFrame(matches) if matches else pd.DataFrame(
            columns=['rid', 'aids', 'sum_adv', 'gap', 'score', 'match_type']
        )
        
        logger.info(f"ë§¤ì¹­ ì™„ë£Œ: {len(matches)}ê±´")
        return result_df
        
    except Exception as e:
        logger.error(f"ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(columns=['rid', 'aids', 'sum_adv', 'gap', 'score', 'match_type'])

# ============== UI êµ¬ì„± ==============

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“ ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "ì—‘ì…€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=["xlsx", "xlsm", "xls"],
        help="xlsx, xlsm, xls í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤. ë§¤í¬ë¡œ íŒŒì¼(xlsm)ì€ ê°’ë§Œ ì½ìŠµë‹ˆë‹¤."
    )
    
    if uploaded_file:
        st.success(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
    
    st.divider()
    
    st.header("ğŸ”§ ë§¤ì¹­ ì„¤ì •")
    
    # ë§¤ì¹­ ì„¤ì •
    matching_config = {
        'use_contract_soft': st.checkbox("ê³„ì•½ID ì¼ì¹˜ ê°€ì¤‘ì¹˜", value=True,
                                         help="ê°™ì€ ê³„ì•½IDë¼ë¦¬ ë§¤ì¹­ ì ìˆ˜ ì¦ê°€"),
        'use_amount': st.checkbox("ê¸ˆì•¡ ì¡°ê±´ ì‚¬ìš©", value=True,
                                 help="ê¸ˆì•¡ í—ˆìš© ë²”ìœ„ ë‚´ì—ì„œë§Œ ë§¤ì¹­"),
        'amount_tol': st.number_input("ê¸ˆì•¡ í—ˆìš© ì˜¤ì°¨(ì›)",
                                     min_value=0, max_value=1000000000,
                                     value=0, step=1000,
                                     help="ì ˆëŒ€ ê¸ˆì•¡ ì°¨ì´ í—ˆìš© ë²”ìœ„"),
        'amount_tol_pct': st.slider("ê¸ˆì•¡ í—ˆìš© ì˜¤ì°¨(%)",
                                   min_value=0, max_value=20, value=1,
                                   help="ìƒëŒ€ ê¸ˆì•¡ ì°¨ì´ í—ˆìš© ë²”ìœ„"),
        'use_date': st.checkbox("ì¼ì ì¡°ê±´ ì‚¬ìš©", value=True,
                               help="ì¼ì ë²”ìœ„ ë‚´ì—ì„œë§Œ ë§¤ì¹­"),
        'date_window': st.slider("ì¼ì ìœˆë„ìš°(Â±ì¼)",
                                 min_value=0, max_value=180, value=30,
                                 help="ë‚ ì§œ ì°¨ì´ í—ˆìš© ë²”ìœ„"),
        'use_party_soft': st.checkbox("ê±°ë˜ì²˜ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜", value=True,
                                     help="ê±°ë˜ì²˜/ë©”ëª¨ í…ìŠ¤íŠ¸ ìœ ì‚¬ì„±ìœ¼ë¡œ ì ìˆ˜ ì¦ê°€"),
        'max_combo': st.slider("ë¶€ë¶„í•© ë§¤ì¹­ ìµœëŒ€ ë¬¶ìŒ ìˆ˜",
                               min_value=1, max_value=5, value=3,
                               help="1ê°œ ì„ ìˆ˜ê¸ˆì— ëŒ€í•´ ìµœëŒ€ ëª‡ ê°œê¹Œì§€ ì„ ê¸‰ê¸ˆ ì¡°í•© ë§¤ì¹­")
    }
    
    st.divider()
    st.header("â„¹ï¸ ë„ì›€ë§")
    with st.expander("ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…"):
        st.markdown("""
        **ë§¤ì¹­ ì ìˆ˜ êµ¬ì„±:**
        - ê¸ˆì•¡ ì •í™•ë„: 40%
        - ë‚ ì§œ ê·¼ì ‘ì„±: 30% 
        - ê³„ì•½ID ì¼ì¹˜: 20%
        - í…ìŠ¤íŠ¸ ìœ ì‚¬ë„: 10%
        
        **ë§¤ì¹­ ìˆœì„œ:**
        1. 1:1 ë§¤ì¹­ ì‹œë„
        2. ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ 1:N ì¡°í•© ë§¤ì¹­ ì‹œë„
        3. ìµœê³  ì ìˆ˜ ë§¤ì¹­ ì„ íƒ
        """)

# ë©”ì¸ í™”ë©´
if uploaded_file is None:
    st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.markdown("""
    ### ğŸ“‹ ì‚¬ìš©ë²•
    1. **ì—‘ì…€ íŒŒì¼ ì¤€ë¹„**: 'ì„ ìˆ˜ê¸ˆ', 'ì„ ê¸‰ê¸ˆ' ì‹œíŠ¸ê°€ í¬í•¨ëœ íŒŒì¼
    2. **íŒŒì¼ ì—…ë¡œë“œ**: ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ ì„ íƒ
    3. **ë°ì´í„° í™•ì¸**: ìë™ìœ¼ë¡œ í‘œì¤€í™”ëœ ë°ì´í„° í™•ì¸
    4. **ë§¤ì¹­ ì„¤ì •**: í•„ìš”ì‹œ ë§¤ì¹­ ì¡°ê±´ ì¡°ì •
    5. **ê²°ê³¼ ë¶„ì„**: ê³„ì•½ë³„ ìƒì„¸ ë‚´ì—­ ë° ìë™ ë§¤ì¹­ ê²°ê³¼ í™•ì¸
    
    ### ğŸ¯ ì£¼ìš” ê¸°ëŠ¥
    - **ìë™ ì»¬ëŸ¼ ì¸ì‹**: ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… ìë™ ë§¤ì¹­
    - **ë°ì´í„° í‘œì¤€í™”**: ê¸ˆì•¡, ë‚ ì§œ ë“± ìë™ ë³€í™˜
    - **ì§€ëŠ¥í˜• ë§¤ì¹­**: AI ê¸°ë°˜ ì„ ìˆ˜ê¸ˆ-ì„ ê¸‰ê¸ˆ ë§¤ì¹­
    - **ì‹œê°í™”**: ì°¨íŠ¸ì™€ ê·¸ë˜í”„ë¡œ ë°ì´í„° ë¶„ì„
    """)
    st.stop()

# ë°ì´í„° ë¡œë“œ
try:
    with st.spinner("ğŸ“Š ì—‘ì…€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        base_data, agg_table, receipts_data, advances_data, validation_info = load_excel_data(uploaded_file.read())
    
    # ë°ì´í„° ê²€ì¦ ì •ë³´ í‘œì‹œ
    if "error" in validation_info:
        st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {validation_info['error']}")
        st.stop()
    
    # ë°ì´í„° ê²€ì¦ ì„±ê³µ ë©”ì‹œì§€
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info(f"ğŸ“„ ê°ì§€ëœ ì‹œíŠ¸: {', '.join(validation_info['ì‹œíŠ¸_ëª©ë¡'])}")
    with col2:
        st.info(f"ğŸ“Š ì›ë³¸ ë°ì´í„°: ì„ ìˆ˜ê¸ˆ {validation_info['ì„ ìˆ˜ê¸ˆ_ì›ë³¸_í–‰ìˆ˜']}ê±´, ì„ ê¸‰ê¸ˆ {validation_info['ì„ ê¸‰ê¸ˆ_ì›ë³¸_í–‰ìˆ˜']}ê±´")
    with col3:
        st.info(f"âœ… í‘œì¤€í™” ì™„ë£Œ: ì„ ìˆ˜ê¸ˆ {validation_info['ì„ ìˆ˜ê¸ˆ_í‘œì¤€í™”_í–‰ìˆ˜']}ê±´, ì„ ê¸‰ê¸ˆ {validation_info['ì„ ê¸‰ê¸ˆ_í‘œì¤€í™”_í–‰ìˆ˜']}ê±´")

except Exception as e:
    st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# KPI ëŒ€ì‹œë³´ë“œ
st.subheader("ğŸ“ˆ ì£¼ìš” ì§€í‘œ")
col1, col2, col3, col4, col5 = st.columns(5)

total_receipts = base_data.loc[base_data['direction'] == 'ì„ ìˆ˜ê¸ˆ', 'amount'].sum()
total_advances = base_data.loc[base_data['direction'] == 'ì„ ê¸‰ê¸ˆ', 'amount'].sum()
total_gap = total_receipts - total_advances
contract_count = agg_table.shape[0]
avg_gap = total_gap / contract_count if contract_count > 0 else 0

with col1:
    st.metric("ğŸ’° ì´ ì„ ìˆ˜ê¸ˆ", f"{total_receipts:,.0f} ì›",
              help="ê³ ê°ìœ¼ë¡œë¶€í„° ë¯¸ë¦¬ ë°›ì€ ì´ ê¸ˆì•¡")
with col2:
    st.metric("ğŸ’¸ ì´ ì„ ê¸‰ê¸ˆ", f"{total_advances:,.0f} ì›",
              help="í˜‘ë ¥ì‚¬ì— ë¯¸ë¦¬ ì§€ê¸‰í•œ ì´ ê¸ˆì•¡")
with col3:
    delta_color = "normal" if total_gap >= 0 else "inverse"
    st.metric("ğŸ“Š ì „ì²´ Gap", f"{total_gap:,.0f} ì›",
              delta=f"í‰ê·  {avg_gap:,.0f}ì›/ê³„ì•½",
              delta_color=delta_color,
              help="ì„ ìˆ˜ê¸ˆ - ì„ ê¸‰ê¸ˆ (ì–‘ìˆ˜ì¼ ë•Œ ìœ ë¦¬)")
with col4:
    st.metric("ğŸ“‹ ê³„ì•½ ìˆ˜", f"{contract_count:,}ê°œ",
              help="ë¶„ì„ëœ ì´ ê³„ì•½ ê±´ìˆ˜")
with col5:
    overdue_count = base_data['overdue_flag'].sum()
    st.metric("âš ï¸ ì—°ì²´ ê±´", f"{overdue_count}ê±´",
              help="ê¸°í•œì´ ê²½ê³¼ëœ ê±°ë˜ ê±´ìˆ˜")

st.divider()

# í•„í„° ë° ê²€ìƒ‰
st.subheader("ğŸ” ê³„ì•½ ê²€ìƒ‰ ë° í•„í„°")

# ê²€ìƒ‰ ì „ ë°ì´í„° ìƒíƒœ í™•ì¸
if not agg_table.empty:
    st.caption(f"ğŸ“Š ì „ì²´ ê³„ì•½ ìˆ˜: {len(agg_table)}ê°œ")
    
    # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ (ë””ë²„ê¹…ìš©)
    with st.expander("ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ë””ë²„ê¹…)"):
        st.write("**ì»¬ëŸ¼ ì •ë³´:**")
        st.write(list(agg_table.columns))
        st.write("**ìƒ˜í”Œ ë°ì´í„°:**")
        st.dataframe(agg_table.head(3))
        
        st.write("**ê° ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ìƒ˜í”Œ:**")
        for col in ["ê³„ì•½ID", "ë‹´ë‹¹ì", "ì£¼ìš”ê±°ë˜ì²˜"]:
            if col in agg_table.columns:
                unique_vals = agg_table[col].astype(str).unique()[:5]
                st.write(f"- {col}: {list(unique_vals)}")

filter_col1, filter_col2, filter_col3, filter_col4 = st.columns([3, 2, 2, 1])

with filter_col1:
    search_query = st.text_input("ğŸ” í†µí•© ê²€ìƒ‰",
                                 placeholder="ê³„ì•½ID, ê±°ë˜ì²˜ëª…, ë‹´ë‹¹ìëª…ìœ¼ë¡œ ê²€ìƒ‰...",
                                 help="ì—¬ëŸ¬ ì¡°ê±´ì„ ë™ì‹œì— ê²€ìƒ‰í•©ë‹ˆë‹¤",
                                 key="search_input")

with filter_col2:
    owner_filter = st.text_input("ğŸ‘¤ ë‹´ë‹¹ì í•„í„°",
                                 placeholder="ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì—¬ëŸ¬ëª… ì…ë ¥",
                                 help="ì˜ˆ: ê¹€ì² ìˆ˜, ì´ì˜í¬",
                                 key="owner_input")

with filter_col3:
    sort_options = ["Gap(ì„ ìˆ˜-ì„ ê¸‰)", "ì„ ìˆ˜ê¸ˆ_í•©ê³„", "ì„ ê¸‰ê¸ˆ_í•©ê³„", "ê³„ì•½ID", "ìµœê·¼ì¼ì", "ê±´ìˆ˜"]
    sort_by = st.selectbox("ğŸ“Š ì •ë ¬ ê¸°ì¤€", sort_options,
                           help="í…Œì´ë¸” ì •ë ¬ ê¸°ì¤€ì„ ì„ íƒí•˜ì„¸ìš”")

with filter_col4:
    show_only_gap = st.checkbox("Gapë§Œ í‘œì‹œ",
                                help="Gapì´ ìˆëŠ” ê³„ì•½ë§Œ í‘œì‹œ")

# ì‹¤ì‹œê°„ í•„í„°ë§ ìƒíƒœ í‘œì‹œ
if search_query or owner_filter:
    st.info(f"ğŸ” ê²€ìƒ‰ ì¡°ê±´: '{search_query}' | ë‹´ë‹¹ì: '{owner_filter}'")

# í•„í„° ì ìš©
try:
    filtered_table = apply_filters(agg_table, search_query, owner_filter)
    
    # í•„í„°ë§ ê²°ê³¼ ë¡œê·¸ í‘œì‹œ
    if search_query or owner_filter:
        filter_info_col1, filter_info_col2 = st.columns(2)
        with filter_info_col1:
            st.caption(f"ğŸ“Š ê²€ìƒ‰ ì „: {len(agg_table)}ê°œ ê³„ì•½")
        with filter_info_col2:
            st.caption(f"ğŸ“Š ê²€ìƒ‰ í›„: {len(filtered_table)}ê°œ ê³„ì•½")
    
    if show_only_gap and not filtered_table.empty:
        before_gap_filter = len(filtered_table)
        filtered_table = filtered_table[filtered_table["Gap(ì„ ìˆ˜-ì„ ê¸‰)"] != 0]
        if search_query or owner_filter or show_only_gap:
            st.caption(f"ğŸ“Š Gap í•„í„° í›„: {len(filtered_table)}ê°œ ê³„ì•½ (í•„í„° ì „: {before_gap_filter}ê°œ)")
    
except Exception as e:
    st.error(f"âŒ í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    logger.error(f"í•„í„°ë§ ì˜ˆì™¸: {e}")
    filtered_table = agg_table

# ì •ë ¬ ì ìš©
if not filtered_table.empty:
    try:
        filtered_table = safe_sort(filtered_table, sort_by)
    except Exception as e:
        st.warning(f"âš ï¸ ì •ë ¬ ì¤‘ ì˜¤ë¥˜: {e}")
        logger.error(f"ì •ë ¬ ì˜ˆì™¸: {e}")

# ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ë„ì›€ë§ í‘œì‹œ
if filtered_table.empty and (search_query or owner_filter):
    st.warning("ğŸ” ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë„ì›€ë§ ì œê³µ
    help_col1, help_col2 = st.columns(2)
    with help_col1:
        st.markdown("""
        **ğŸ”§ ê²€ìƒ‰ íŒ:**
        - ë¶€ë¶„ ë‹¨ì–´ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”
        - ëŒ€ì†Œë¬¸ìëŠ” êµ¬ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
        - íŠ¹ìˆ˜ë¬¸ì ì—†ì´ ê²€ìƒ‰í•´ë³´ì„¸ìš”
        """)
    
    with help_col2:
        if not agg_table.empty:
            st.markdown("**ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì˜ˆì‹œ:**")
            sample_contracts = agg_table["ê³„ì•½ID"].head(3).tolist()
            sample_owners = agg_table["ë‹´ë‹¹ì"].dropna().head(3).tolist()
            
            if sample_contracts:
                st.write(f"ê³„ì•½ID: {', '.join(map(str, sample_contracts))}")
            if sample_owners:
                st.write(f"ë‹´ë‹¹ì: {', '.join(sample_owners)}")
    
    # í•„í„° ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ê²€ìƒ‰ ì¡°ê±´ ì´ˆê¸°í™”"):
        st.experimental_rerun()

# í…Œì´ë¸” í‘œì‹œ
st.subheader("ğŸ“‹ ê³„ì•½ë³„ ì§‘ê³„ í˜„í™©")

if filtered_table.empty and not (search_query or owner_filter):
    st.warning("ğŸ“Š í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ íŒŒì¼ì˜ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
elif not filtered_table.empty:
    # í…Œì´ë¸” ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•œ í•¨ìˆ˜
    def style_dataframe(df):
        def color_gap(val):
            if pd.isna(val) or val == 0:
                return 'background-color: #f0f0f0'
            elif val > 0:
                return 'background-color: #d4edda; color: #155724'  # ë…¹ìƒ‰ (ìœ ë¦¬)
            else:
                return 'background-color: #f8d7da; color: #721c24'  # ë¹¨ê°„ìƒ‰ (ë¶ˆë¦¬)
        
        styled = df.style.applymap(color_gap, subset=['Gap(ì„ ìˆ˜-ì„ ê¸‰)'])
        
        # ê¸ˆì•¡ ì»¬ëŸ¼ í¬ë§·íŒ…
        money_cols = ['ì„ ìˆ˜ê¸ˆ_í•©ê³„', 'ì„ ê¸‰ê¸ˆ_í•©ê³„', 'Gap(ì„ ìˆ˜-ì„ ê¸‰)']
        for col in money_cols:
            if col in df.columns:
                styled = styled.format({col: '{:,.0f}'})
        
        return styled
    
    styled_table = style_dataframe(filtered_table)
    
    st.dataframe(
        styled_table,
        use_container_width=True,
        height=400,
        column_config={
            "ê³„ì•½ID": st.column_config.TextColumn("ê³„ì•½ID", width="medium"),
            "ì„ ìˆ˜ê¸ˆ_í•©ê³„": st.column_config.NumberColumn("ì„ ìˆ˜ê¸ˆ í•©ê³„", format="â‚©%.0f"),
            "ì„ ê¸‰ê¸ˆ_í•©ê³„": st.column_config.NumberColumn("ì„ ê¸‰ê¸ˆ í•©ê³„", format="â‚©%.0f"),
            "Gap(ì„ ìˆ˜-ì„ ê¸‰)": st.column_config.NumberColumn("Gap", format="â‚©%.0f"),
            "ìµœê·¼ì¼ì": st.column_config.DateColumn("ìµœê·¼ ì¼ì"),
            "ê±´ìˆ˜": st.column_config.NumberColumn("ê±°ë˜ ê±´ìˆ˜", format="%dê±´")
        }
    )
    
    # ìš”ì•½ í†µê³„
    st.caption(f"ğŸ“Š ì´ {len(filtered_table)}ê°œ ê³„ì•½ | "
              f"ì–‘ì˜ Gap: {len(filtered_table[filtered_table['Gap(ì„ ìˆ˜-ì„ ê¸‰)'] > 0])}ê°œ | "
              f"ìŒì˜ Gap: {len(filtered_table[filtered_table['Gap(ì„ ìˆ˜-ì„ ê¸‰)'] < 0])}ê°œ | "
              f"Gap ì—†ìŒ: {len(filtered_table[filtered_table['Gap(ì„ ìˆ˜-ì„ ê¸‰)'] == 0])}ê°œ")

# ê³„ì•½ ìƒì„¸ ë¶„ì„
st.divider()
st.subheader("ğŸ”¬ ê³„ì•½ ìƒì„¸ ë¶„ì„")

contract_list = ["(ê³„ì•½ì„ ì„ íƒí•˜ì„¸ìš”)"] + filtered_table["ê³„ì•½ID"].tolist()
selected_contract = st.selectbox("ğŸ“‹ ë¶„ì„í•  ê³„ì•½ ì„ íƒ", contract_list,
                                 help="ìƒì„¸ ë¶„ì„ì„ ì›í•˜ëŠ” ê³„ì•½ì„ ì„ íƒí•˜ì„¸ìš”")

if selected_contract and selected_contract != "(ê³„ì•½ì„ ì„ íƒí•˜ì„¸ìš”)":
    # ì„ íƒëœ ê³„ì•½ ë°ì´í„°
    contract_detail = base_data[base_data["contract_id"] == selected_contract].copy()
    
    if contract_detail.empty:
        st.error("âŒ ì„ íƒëœ ê³„ì•½ì˜ ìƒì„¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ê³„ì•½ ìš”ì•½ ì •ë³´
        receipts_sum = contract_detail.loc[contract_detail["direction"] == "ì„ ìˆ˜ê¸ˆ", "amount"].sum()
        advances_sum = contract_detail.loc[contract_detail["direction"] == "ì„ ê¸‰ê¸ˆ", "amount"].sum()
        gap = receipts_sum - advances_sum
        
        # ë©”íŠ¸ë¦­ í‘œì‹œ
        metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
        with metric_col1:
            st.metric("ğŸ’° ì„ ìˆ˜ê¸ˆ ì´ê³„", f"{receipts_sum:,.0f} ì›",
                      help="ê³ ê°ìœ¼ë¡œë¶€í„° ë°›ì€ ì´ ê¸ˆì•¡")
        with metric_col2:
            st.metric("ğŸ’¸ ì„ ê¸‰ê¸ˆ ì´ê³„", f"{advances_sum:,.0f} ì›",
                      help="í˜‘ë ¥ì‚¬ì— ì§€ê¸‰í•œ ì´ ê¸ˆì•¡")
        with metric_col3:
            delta_color = "normal" if gap >= 0 else "inverse"
            st.metric("ğŸ“Š Gap", f"{gap:,.0f} ì›",
                      delta=f"{gap/receipts_sum*100:.1f}%" if receipts_sum > 0 else "0%",
                      delta_color=delta_color,
                      help="ì„ ìˆ˜ê¸ˆ - ì„ ê¸‰ê¸ˆ")
        with metric_col4:
            total_count = len(contract_detail)
            st.metric("ğŸ“‹ ì´ ê±°ë˜ ê±´ìˆ˜", f"{total_count}ê±´",
                      help="í•´ë‹¹ ê³„ì•½ì˜ ì´ ê±°ë˜ ê±´ìˆ˜")
        
        # ìƒì„¸ ì •ë³´ íƒ­
        detail_tab1, detail_tab2, detail_tab3, detail_tab4 = st.tabs([
            "ğŸ“Š ì„ ìˆ˜ê¸ˆ ìƒì„¸", "ğŸ“ˆ ì„ ê¸‰ê¸ˆ ìƒì„¸", "ğŸ¤– ìë™ ë§¤ì¹­", "ğŸ“‰ ì‹œê°í™” ë¶„ì„"
        ])
        
        with detail_tab1:
            receipts_detail = contract_detail[contract_detail["direction"] == "ì„ ìˆ˜ê¸ˆ"].copy()
            
            if receipts_detail.empty:
                st.info("â„¹ï¸ í•´ë‹¹ ê³„ì•½ì— ì„ ìˆ˜ê¸ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.write(f"**ì„ ìˆ˜ê¸ˆ ê±°ë˜ ë‚´ì—­** ({len(receipts_detail)}ê±´)")
                
                # ë‚ ì§œ í¬ë§·íŒ…
                receipts_display = receipts_detail.copy()
                receipts_display["date"] = pd.to_datetime(receipts_display["date"]).dt.strftime('%Y-%m-%d')
                receipts_display = receipts_display.fillna('')
                
                st.dataframe(
                    receipts_display[STANDARD_COLS].rename(columns={
                        "contract_id": "ê³„ì•½ID", "direction": "êµ¬ë¶„", "amount": "ê¸ˆì•¡",
                        "date": "ì¼ì", "party": "ê±°ë˜ì²˜", "owner": "ë‹´ë‹¹ì",
                        "status": "ìƒíƒœ", "note": "ë¹„ê³ ", "overdue_flag": "ì—°ì²´ì—¬ë¶€"
                    }),
                    use_container_width=True,
                    column_config={
                        "ê¸ˆì•¡": st.column_config.NumberColumn("ê¸ˆì•¡", format="â‚©%.0f"),
                        "ì—°ì²´ì—¬ë¶€": st.column_config.CheckboxColumn("ì—°ì²´")
                    }
                )
                
                # ì›”ë³„ ì§‘ê³„ ì°¨íŠ¸
                if not receipts_detail.empty:
                    receipts_chart_data = receipts_detail.copy()
                    receipts_chart_data['date'] = pd.to_datetime(receipts_chart_data['date'])
                    receipts_chart_data = receipts_chart_data.dropna(subset=['date'])
                    
                    if not receipts_chart_data.empty:
                        monthly_receipts = (receipts_chart_data
                                            .groupby(receipts_chart_data['date'].dt.to_period('M'))['amount']
                                            .sum()
                                            .reset_index())
                        monthly_receipts['date'] = monthly_receipts['date'].dt.to_timestamp()
                        
                        st.subheader("ğŸ“Š ì›”ë³„ ì„ ìˆ˜ê¸ˆ ì¶”ì´")
                        st.bar_chart(monthly_receipts.set_index('date')['amount'])
        
        with detail_tab2:
            advances_detail = contract_detail[contract_detail["direction"] == "ì„ ê¸‰ê¸ˆ"].copy()
            
            if advances_detail.empty:
                st.info("â„¹ï¸ í•´ë‹¹ ê³„ì•½ì— ì„ ê¸‰ê¸ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.write(f"**ì„ ê¸‰ê¸ˆ ê±°ë˜ ë‚´ì—­** ({len(advances_detail)}ê±´)")
                
                # ë‚ ì§œ í¬ë§·íŒ…
                advances_display = advances_detail.copy()
                advances_display["date"] = pd.to_datetime(advances_display["date"]).dt.strftime('%Y-%m-%d')
                advances_display = advances_display.fillna('')
                
                st.dataframe(
                    advances_display[STANDARD_COLS].rename(columns={
                        "contract_id": "ê³„ì•½ID", "direction": "êµ¬ë¶„", "amount": "ê¸ˆì•¡",
                        "date": "ì¼ì", "party": "ê±°ë˜ì²˜", "owner": "ë‹´ë‹¹ì",
                        "status": "ìƒíƒœ", "note": "ë¹„ê³ ", "overdue_flag": "ì—°ì²´ì—¬ë¶€"
                    }),
                    use_container_width=True,
                    column_config={
                        "ê¸ˆì•¡": st.column_config.NumberColumn("ê¸ˆì•¡", format="â‚©%.0f"),
                        "ì—°ì²´ì—¬ë¶€": st.column_config.CheckboxColumn("ì—°ì²´")
                    }
                )
                
                # ì›”ë³„ ì§‘ê³„ ì°¨íŠ¸
                if not advances_detail.empty:
                    advances_chart_data = advances_detail.copy()
                    advances_chart_data['date'] = pd.to_datetime(advances_chart_data['date'])
                    advances_chart_data = advances_chart_data.dropna(subset=['date'])
                    
                    if not advances_chart_data.empty:
                        monthly_advances = (advances_chart_data
                                            .groupby(advances_chart_data['date'].dt.to_period('M'))['amount']
                                            .sum()
                                            .reset_index())
                        monthly_advances['date'] = monthly_advances['date'].dt.to_timestamp()
                        
                        st.subheader("ğŸ“Š ì›”ë³„ ì„ ê¸‰ê¸ˆ ì¶”ì´")
                        st.bar_chart(monthly_advances.set_index('date')['amount'])
        
        with detail_tab3:
            contract_receipts = contract_detail[contract_detail["direction"] == "ì„ ìˆ˜ê¸ˆ"].copy()
            all_advances = base_data[base_data["direction"] == "ì„ ê¸‰ê¸ˆ"].copy()
            
            if contract_receipts.empty or all_advances.empty:
                st.info("â„¹ï¸ ë§¤ì¹­ì„ ìœ„í•œ ì„ ìˆ˜ê¸ˆ ë˜ëŠ” ì„ ê¸‰ê¸ˆ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            else:
                st.write("**ğŸ¤– AI ìë™ ë§¤ì¹­ ê²°ê³¼**")
                
                with st.spinner("ğŸ”„ ìµœì  ë§¤ì¹­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    matching_result = compute_matches_optimized(
                        contract_receipts, all_advances, matching_config
                    )
                
                if matching_result.empty:
                    st.warning("âš ï¸ í˜„ì¬ ì„¤ì • ì¡°ê±´ìœ¼ë¡œëŠ” ìë™ ë§¤ì¹­ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. "
                              "ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ í—ˆìš© ì˜¤ì°¨ë‚˜ ìœˆë„ìš° ë²”ìœ„ë¥¼ ë„“í˜€ë³´ì„¸ìš”.")
                else:
                    # ë§¤ì¹­ ê²°ê³¼ í‘œì‹œìš© ë°ì´í„° ì¤€ë¹„
                    display_matches = []
                    contract_receipts_indexed = contract_receipts.reset_index(drop=True)
                    all_advances_indexed = all_advances.reset_index(drop=True)
                    
                    for _, match in matching_result.iterrows():
                        receipt_info = contract_receipts_indexed.loc[match['rid']]
                        advance_infos = all_advances_indexed.loc[match['aids']]
                        
                        if len(match['aids']) == 1:
                            advance_desc = f"#{match['aids'][0]}: {advance_infos['amount']:,.0f}ì›"
                            advance_party = advance_infos['party']
                            advance_date = advance_infos['date']
                        else:
                            advance_desc = ", ".join([
                                f"#{aid}: {amt:,.0f}ì›"
                                for aid, amt in zip(match['aids'], advance_infos['amount'])
                            ])
                            advance_party = " + ".join(advance_infos['party'].unique())
                            advance_date = advance_infos['date'].max()
                        
                        display_matches.append({
                            "ì„ ìˆ˜ê¸ˆ_ê¸ˆì•¡": f"{receipt_info['amount']:,.0f}ì›",
                            "ì„ ìˆ˜ê¸ˆ_ì¼ì": receipt_info['date'].strftime('%Y-%m-%d') if pd.notna(receipt_info['date']) else '',
                            "ì„ ìˆ˜ê¸ˆ_ê±°ë˜ì²˜": receipt_info['party'],
                            "ì„ ìˆ˜ê¸ˆ_ë¹„ê³ ": receipt_info['note'][:50] + "..." if len(str(receipt_info['note'])) > 50 else receipt_info['note'],
                            "ë§¤ì¹­ëœ_ì„ ê¸‰ê¸ˆ": advance_desc,
                            "ì„ ê¸‰ê¸ˆ_ê±°ë˜ì²˜": advance_party,
                            "ì„ ê¸‰ê¸ˆ_í•©ê³„": f"{match['sum_adv']:,.0f}ì›",
                            "ì°¨ì´(Gap)": f"{match['gap']:,.0f}ì›",
                            "ë§¤ì¹­_ìœ í˜•": match['match_type'],
                            "ì‹ ë¢°ë„": f"{match['score']:.2f}",
                        })
                    
                    matches_df = pd.DataFrame(display_matches)
                    
                    # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ êµ¬ë¶„
                    def color_confidence(val):
                        try:
                            score = float(val)
                            if score >= 0.8:
                                return 'background-color: #d4edda; color: #155724'  # ë†’ìŒ: ë…¹ìƒ‰
                            elif score >= 0.5:
                                return 'background-color: #fff3cd; color: #856404'  # ë³´í†µ: ë…¸ë€ìƒ‰
                            else:
                                return 'background-color: #f8d7da; color: #721c24'  # ë‚®ìŒ: ë¹¨ê°„ìƒ‰
                        except:
                            return ''
                    
                    styled_matches = matches_df.style.applymap(color_confidence, subset=['ì‹ ë¢°ë„'])
                    
                    st.dataframe(styled_matches, use_container_width=True, height=400)
                    
                    # ë§¤ì¹­ í†µê³„
                    high_conf = len(matching_result[matching_result['score'] >= 0.8])
                    med_conf = len(matching_result[(matching_result['score'] >= 0.5) & (matching_result['score'] < 0.8)])
                    low_conf = len(matching_result[matching_result['score'] < 0.5])
                    
                    stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                    with stat_col1:
                        st.metric("ğŸ¯ ê³ ì‹ ë¢°ë„", f"{high_conf}ê±´", help="ì‹ ë¢°ë„ â‰¥ 0.8")
                    with stat_col2:
                        st.metric("âš–ï¸ ì¤‘ì‹ ë¢°ë„", f"{med_conf}ê±´", help="0.5 â‰¤ ì‹ ë¢°ë„ < 0.8")
                    with stat_col3:
                        st.metric("âš ï¸ ì €ì‹ ë¢°ë„", f"{low_conf}ê±´", help="ì‹ ë¢°ë„ < 0.5")
                    with stat_col4:
                        matched_rids = set(matching_result['rid'])
                        unmatched = len(contract_receipts) - len(matched_rids)
                        st.metric("â“ ë¯¸ë§¤ì¹­", f"{unmatched}ê±´", help="ë§¤ì¹­ë˜ì§€ ì•Šì€ ì„ ìˆ˜ê¸ˆ")
                    
                    # ë¯¸ë§¤ì¹­ ì„ ìˆ˜ê¸ˆ í‘œì‹œ
                    if unmatched > 0:
                        with st.expander(f"ğŸ” ë¯¸ë§¤ì¹­ ì„ ìˆ˜ê¸ˆ ë³´ê¸° ({unmatched}ê±´)"):
                            matched_rids = set(matching_result['rid'])
                            unmatched_receipts = contract_receipts_indexed[
                                ~contract_receipts_indexed.index.isin(matched_rids)
                            ].copy()
                            
                            unmatched_receipts["date"] = pd.to_datetime(unmatched_receipts["date"]).dt.strftime('%Y-%m-%d')
                            unmatched_receipts = unmatched_receipts.fillna('')
                            
                            st.dataframe(
                                unmatched_receipts[["amount", "date", "party", "note"]].rename(columns={
                                    "amount": "ê¸ˆì•¡", "date": "ì¼ì", "party": "ê±°ë˜ì²˜", "note": "ë¹„ê³ "
                                }),
                                use_container_width=True,
                                column_config={
                                    "ê¸ˆì•¡": st.column_config.NumberColumn("ê¸ˆì•¡", format="â‚©%.0f")
                                }
                            )
        
        with detail_tab4:
            st.write("**ğŸ“Š ê³„ì•½ ì‹œê°í™” ë¶„ì„**")
            
            if len(contract_detail) < 2:
                st.info("â„¹ï¸ ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ìµœì†Œ 2ê±´ ì´ìƒ í•„ìš”)")
            else:
                # ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
                chart_data = contract_detail.copy()
                chart_data['date'] = pd.to_datetime(chart_data['date'])
                chart_data = chart_data.dropna(subset=['date'])
                
                if not chart_data.empty:
                    # ì¼ìë³„ ëˆ„ì  ì”ì•¡ ê³„ì‚°
                    chart_data = chart_data.sort_values('date')
                    chart_data['signed_amount'] = chart_data.apply(
                        lambda row: row['amount'] if row['direction'] == 'ì„ ìˆ˜ê¸ˆ' else -row['amount'],
                        axis=1
                    )
                    chart_data['cumulative_balance'] = chart_data['signed_amount'].cumsum()
                    
                    # ì„ ìˆ˜ê¸ˆ/ì„ ê¸‰ê¸ˆ ë¶„ë¦¬ ì°¨íŠ¸
                    viz_col1, viz_col2 = st.columns(2)
                    
                    with viz_col1:
                        st.subheader("ğŸ“ˆ ì¼ìë³„ ëˆ„ì  ì”ì•¡ ì¶”ì´")
                        balance_chart = chart_data[['date', 'cumulative_balance']].set_index('date')
                        st.line_chart(balance_chart)
                        
                    with viz_col2:
                        st.subheader("âš–ï¸ ì„ ìˆ˜ê¸ˆ vs ì„ ê¸‰ê¸ˆ")
                        direction_summary = contract_detail.groupby('direction')['amount'].sum()
                        
                        chart_dict = direction_summary.to_dict()
                        st.bar_chart(chart_dict)
                    
                    # ì›”ë³„ ì§‘ê³„ ë¹„êµ
                    if len(chart_data) > 5:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ
                        st.subheader("ğŸ“… ì›”ë³„ ì„ ìˆ˜ê¸ˆ vs ì„ ê¸‰ê¸ˆ ë¹„êµ")
                        
                        monthly_comparison = (chart_data
                                              .groupby([chart_data['date'].dt.to_period('M'), 'direction'])['amount']
                                              .sum()
                                              .unstack(fill_value=0))
                        
                        if not monthly_comparison.empty:
                            monthly_comparison.index = monthly_comparison.index.to_timestamp()
                            st.bar_chart(monthly_comparison)
                        
                        # ê±°ë˜ì²˜ë³„ ë¶„ì„
                        if len(chart_data['party'].unique()) > 1:
                            st.subheader("ğŸ¢ ê±°ë˜ì²˜ë³„ ê¸ˆì•¡ ë¶„ì„")
                            party_analysis = (chart_data.groupby(['party', 'direction'])['amount']
                                              .sum().unstack(fill_value=0))
                            
                            if not party_analysis.empty:
                                st.bar_chart(party_analysis)
                else:
                    st.info("â„¹ï¸ ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# í‘¸í„°
st.divider()
st.markdown("---")

footer_col1, footer_col2 = st.columns(2)
with footer_col1:
    st.markdown("""
    ### ğŸ› ï¸ ê¸°ìˆ  ì •ë³´
    - **Python**: Pandas, Streamlit
    - **ì•Œê³ ë¦¬ì¦˜**: ë‹¤ì¤‘ ì¡°ê±´ ë§¤ì¹­, í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¶„ì„
    - **ë°ì´í„° ì²˜ë¦¬**: ìë™ í‘œì¤€í™”, ì‹¤ì‹œê°„ ì§‘ê³„
    """)

with footer_col2:
    st.markdown("""
    ### ğŸ“ ì§€ì›
    - **ì„¤ì¹˜**: `pip install streamlit pandas openpyxl xlrd xlsxwriter`
    - **ì‹¤í–‰**: `streamlit run app_improved.py`
    - **ë¬¸ì œ í•´ê²°**: ë¡œê·¸ í™•ì¸ ë° ë°ì´í„° ê²€ì¦
    """)

# ë””ë²„ê¹… ì •ë³´ (ê°œë°œììš©) - ë” ìì„¸í•œ ì •ë³´
if st.checkbox("ğŸ”§ ê²€ìƒ‰ ë””ë²„ê¹… ì •ë³´ í‘œì‹œ", help="ê²€ìƒ‰ì´ ì•ˆ ë  ë•Œ ë¬¸ì œ ì§„ë‹¨ìš©"):
    with st.expander("ğŸ” ê²€ìƒ‰ ìƒíƒœ ì§„ë‹¨"):
        st.write("**ê²€ìƒ‰ ì¡°ê±´:**")
        st.json({
            "ê²€ìƒ‰ì–´": search_query,
            "ë‹´ë‹¹ì_í•„í„°": owner_filter,
            "Gapë§Œ_í‘œì‹œ": show_only_gap,
            "ì •ë ¬_ê¸°ì¤€": sort_by
        })
        
        st.write("**ë°ì´í„° ìƒíƒœ:**")
        if not agg_table.empty:
            st.json({
                "ì „ì²´_ë°ì´í„°_ê±´ìˆ˜": len(agg_table),
                "ì»¬ëŸ¼_ëª©ë¡": list(agg_table.columns),
                "ê³„ì•½ID_ìƒ˜í”Œ": agg_table["ê³„ì•½ID"].head(3).tolist() if "ê³„ì•½ID" in agg_table.columns else [],
                "ë‹´ë‹¹ì_ìƒ˜í”Œ": agg_table["ë‹´ë‹¹ì"].dropna().head(3).tolist() if "ë‹´ë‹¹ì" in agg_table.columns else [],
                "ê±°ë˜ì²˜_ìƒ˜í”Œ": agg_table["ì£¼ìš”ê±°ë˜ì²˜"].dropna().head(3).tolist() if "ì£¼ìš”ê±°ë˜ì²˜" in agg_table.columns else []
            })
            
            # ì‹¤ì œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            if search_query:
                st.write("**ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼:**")
                for col in ["ê³„ì•½ID", "ì£¼ìš”ê±°ë˜ì²˜", "ë‹´ë‹¹ì"]:
                    if col in agg_table.columns:
                        test_result = agg_table[col].astype(str).str.contains(search_query, case=False, na=False, regex=False).sum()
                        st.write(f"- {col}ì—ì„œ '{search_query}' ë§¤ì¹˜: {test_result}ê±´")
                
                # ì „ì²´ ë°ì´í„°ì—ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
                all_matches = 0
                for col in ["ê³„ì•½ID", "ì£¼ìš”ê±°ë˜ì²˜", "ë‹´ë‹¹ì"]:
                    if col in agg_table.columns:
                        matches = agg_table[col].astype(str).str.contains(search_query, case=False, na=False, regex=False).sum()
                        all_matches += matches
                
                st.write(f"**ì´ ë§¤ì¹˜ ê±´ìˆ˜: {all_matches}ê±´**")
                
                if all_matches == 0:
                    st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
                    st.write("1. ê²€ìƒ‰ì–´ ì² ì í™•ì¸")
                    st.write("2. ë¶€ë¶„ ë‹¨ì–´ë¡œ ê²€ìƒ‰ (ì˜ˆ: 'í”„ë¡œì íŠ¸' â†’ 'PJT')")
                    st.write("3. ìˆ«ìë§Œìœ¼ë¡œ ê²€ìƒ‰ (ì˜ˆ: '123')")
        else:
            st.error("âŒ ì§‘ê³„ í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        st.write("**í•„í„°ë§ í›„ ê²°ê³¼:**")
        st.json({
            "í•„í„°ë§_í›„_ê±´ìˆ˜": len(filtered_table),
            "ì›ë³¸_ëŒ€ë¹„_ë¹„ìœ¨": f"{len(filtered_table)/len(agg_table)*100:.1f}%" if len(agg_table) > 0 else "0%"
        })

# ë¹ ë¥¸ ê²€ìƒ‰ ë„ìš°ë¯¸
if not agg_table.empty and (search_query == "" or len(filtered_table) == 0):
    st.info("ğŸ’¡ **ë¹ ë¥¸ ê²€ìƒ‰:** ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒ˜í”Œ ê²€ìƒ‰ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
    
    quick_col1, quick_col2, quick_col3 = st.columns(3)
    
    with quick_col1:
        if "ê³„ì•½ID" in agg_table.columns and not agg_table["ê³„ì•½ID"].empty:
            sample_contract = str(agg_table["ê³„ì•½ID"].iloc[0])[:5]  # ì²˜ìŒ 5ê¸€ì
            if st.button(f"ğŸ” '{sample_contract}' ê²€ìƒ‰"):
                st.experimental_set_query_params(search=sample_contract)
                st.experimental_rerun()
    
    with quick_col2:
        if "ë‹´ë‹¹ì" in agg_table.columns:
            valid_owners = agg_table["ë‹´ë‹¹ì"].dropna()
            valid_owners = valid_owners[valid_owners.astype(str).str.len() > 0]
            if not valid_owners.empty:
                sample_owner = str(valid_owners.iloc[0])
                if st.button(f"ğŸ‘¤ '{sample_owner}' ê²€ìƒ‰"):
                    st.experimental_set_query_params(owner=sample_owner)
                    st.experimental_rerun()
    
    with quick_col3:
        if "ì£¼ìš”ê±°ë˜ì²˜" in agg_table.columns:
            valid_parties = agg_table["ì£¼ìš”ê±°ë˜ì²˜"].dropna()
            valid_parties = valid_parties[valid_parties.astype(str).str.len() > 0]
            if not valid_parties.empty:
                sample_party = str(valid_parties.iloc[0])[:10]  # ì²˜ìŒ 10ê¸€ì
                if st.button(f"ğŸ¢ '{sample_party}' ê²€ìƒ‰"):
                    st.experimental_set_query_params(party=sample_party)
                    st.experimental_rerun()

if st.checkbox("ğŸ”§ ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ", help="ì‹œìŠ¤í…œ ìƒíƒœ ë° ë°ì´í„° êµ¬ì¡° í™•ì¸"):
    with st.expander("ğŸ” ì‹œìŠ¤í…œ ì •ë³´"):
        st.write("**ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´:**")
        if uploaded_file:
            st.json({
                "íŒŒì¼ëª…": uploaded_file.name,
                "íŒŒì¼í¬ê¸°": f"{uploaded_file.size:,} bytes",
                "íŒŒì¼íƒ€ì…": uploaded_file.type
            })
        
        st.write("**ë°ì´í„° ê²€ì¦ ì •ë³´:**")
        if 'validation_info' in locals():
            st.json(validation_info)
        
        if not base_data.empty:
            st.write("**ê¸°ë³¸ ë°ì´í„° êµ¬ì¡°:**")
            st.json({
                "ì´_í–‰_ìˆ˜": len(base_data),
                "ì»¬ëŸ¼": list(base_data.columns),
                "ì„ ìˆ˜ê¸ˆ_ê±´ìˆ˜": len(base_data[base_data["direction"] == "ì„ ìˆ˜ê¸ˆ"]),
                "ì„ ê¸‰ê¸ˆ_ê±´ìˆ˜": len(base_data[base_data["direction"] == "ì„ ê¸‰ê¸ˆ"]),
                "ê³ ìœ _ê³„ì•½_ìˆ˜": base_data["contract_id"].nunique()
            })
            
            st.write("**ë°ì´í„° ìƒ˜í”Œ:**")
            st.dataframe(base_data.head(), use_container_width=True)
        
        if not agg_table.empty:
            st.write("**ì§‘ê³„ í…Œì´ë¸” êµ¬ì¡°:**")
            st.json({
                "í–‰_ìˆ˜": len(agg_table),
                "ì»¬ëŸ¼": list(agg_table.columns),
                "ë°ì´í„°_íƒ€ì…": {col: str(dtype) for col, dtype in agg_table.dtypes.items()}
            })
        
        st.write("**ë§¤ì¹­ ì„¤ì •:**")
        if 'matching_config' in locals():
            st.json(matching_config)

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
try:
    import psutil
    import os
    
    if st.checkbox("âš¡ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§", help="ë©”ëª¨ë¦¬ ë° CPU ì‚¬ìš©ëŸ‰ í™•ì¸"):
        performance_col1, performance_col2, performance_col3 = st.columns(3)
        
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        cpu_percent = process.cpu_percent()
        
        with performance_col1:
            st.metric("ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{memory_info.rss / 1024 / 1024:.1f} MB")
        
        with performance_col2:
            st.metric("ğŸ”¥ CPU ì‚¬ìš©ë¥ ", f"{cpu_percent:.1f}%")
        
        with performance_col3:
            if 'base_data' in locals():
                data_size = len(base_data) if not base_data.empty else 0
                st.metric("ğŸ“Š ì²˜ë¦¬ëœ í–‰", f"{data_size:,}ê°œ")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬ ë²„íŠ¼
        if st.button("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬"):
            import gc
            gc.collect()
            st.success("ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
            
except ImportError:
    st.info("psutil ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ê³ ê¸‰ ë°ì´í„° ë¶„ì„ ë„êµ¬
if not base_data.empty:
    with st.expander("ğŸ“ˆ ê³ ê¸‰ ë°ì´í„° ë¶„ì„"):
        analysis_col1, analysis_col2 = st.columns(2)
        
        with analysis_col1:
            st.write("**ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸:**")
            
            # ê²°ì¸¡ê°’ ë¶„ì„
            missing_data = {}
            for col in base_data.columns:
                missing_count = base_data[col].isna().sum()
                missing_pct = (missing_count / len(base_data)) * 100
                missing_data[col] = f"{missing_count}ê°œ ({missing_pct:.1f}%)"
            
            st.json(missing_data)
        
        with analysis_col2:
            st.write("**ê¸ˆì•¡ ë¶„í¬ í†µê³„:**")
            
            amount_stats = base_data["amount"].describe()
            st.json({
                "ìµœì†Œê°’": f"{amount_stats['min']:,.0f}ì›",
                "ìµœëŒ€ê°’": f"{amount_stats['max']:,.0f}ì›",
                "í‰ê· ": f"{amount_stats['mean']:,.0f}ì›",
                "ì¤‘ê°„ê°’": f"{amount_stats['50%']:,.0f}ì›"
            })
        
        # ì´ìƒì¹˜ ê°ì§€
        if st.button("ğŸ” ì´ìƒì¹˜ ê°ì§€"):
            Q1 = base_data["amount"].quantile(0.25)
            Q3 = base_data["amount"].quantile(0.75)
            IQR = Q3 - Q1
            
            outliers = base_data[
                (base_data["amount"] < Q1 - 1.5 * IQR) |
                (base_data["amount"] > Q3 + 1.5 * IQR)
            ]
            
            if not outliers.empty:
                st.warning(f"âš ï¸ {len(outliers)}ê±´ì˜ ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.dataframe(outliers[["contract_id", "direction", "amount", "date"]],
                            use_container_width=True)
            else:
                st.success("âœ… ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ë°ì´í„° ë‚´ë³´ë‚´ê¸° ë„êµ¬
if not base_data.empty:
    with st.expander("ğŸ“ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"):
        export_col1, export_col2, export_col3 = st.columns(3)
        
        with export_col1:
            if st.button("ğŸ“Š ì§‘ê³„ í…Œì´ë¸” ë‹¤ìš´ë¡œë“œ (CSV)"):
                if not agg_table.empty:
                    csv_data = agg_table.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ì§‘ê³„_í…Œì´ë¸”_ë‹¤ìš´ë¡œë“œ.csv",
                        data=csv_data,
                        file_name=f"aggregation_table_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
        
        with export_col2:
            if st.button("ğŸ“‹ ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)"):
                csv_data = base_data.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ì „ì²´_ë°ì´í„°_ë‹¤ìš´ë¡œë“œ.csv",
                    data=csv_data,
                    file_name=f"full_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        with export_col3:
            if st.button("ğŸ” ê²€ìƒ‰ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)"):
                if not filtered_table.empty:
                    csv_data = filtered_table.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ê²€ìƒ‰_ê²°ê³¼_ë‹¤ìš´ë¡œë“œ.csv",
                        data=csv_data,
                        file_name=f"search_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )

# ì‹¤ì‹œê°„ ë¡œê·¸ ë·°ì–´ (ê°œë°œìš©)
if st.checkbox("ğŸ“‹ ì‹¤ì‹œê°„ ë¡œê·¸ ë³´ê¸°", help="ì‹œìŠ¤í…œ ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸"):
    log_placeholder = st.empty()
    
    # ë¡œê·¸ í•¸ë“¤ëŸ¬ ì¶”ê°€ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë” ì •êµí•œ ë¡œê·¸ ì‹œìŠ¤í…œ í•„ìš”)
    if hasattr(st.session_state, 'logs'):
        with log_placeholder.container():
            st.text_area("ì‹œìŠ¤í…œ ë¡œê·¸",
                         value="\n".join(st.session_state.logs[-50:]),  # ìµœê·¼ 50ì¤„ë§Œ í‘œì‹œ
                         height=200)
    else:
        st.info("ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ìë™ ìƒˆë¡œê³ ì¹¨ (ì„ íƒì )
if st.checkbox("ğŸ”„ ìë™ ìƒˆë¡œê³ ì¹¨ (30ì´ˆ)", help="30ì´ˆë§ˆë‹¤ ìë™ìœ¼ë¡œ í™”ë©´ ìƒˆë¡œê³ ì¹¨"):
    import time
    
    # JavaScriptë¥¼ ì´ìš©í•œ ìë™ ìƒˆë¡œê³ ì¹¨
    st.markdown("""
    <script>
    setTimeout(function(){
        window.location.reload();
    }, 30000);
    </script>
    """, unsafe_allow_html=True)
    
    st.info("â° 30ì´ˆ í›„ ìë™ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨ë©ë‹ˆë‹¤.")

# ìºì‹œ ê´€ë¦¬ ë„êµ¬
cache_col1, cache_col2, cache_col3 = st.columns(3)

with cache_col1:
    if st.button("ğŸ—‘ï¸ ë°ì´í„° ìºì‹œ ì´ˆê¸°í™”"):
        st.cache_data.clear()
        st.success("âœ… ë°ì´í„° ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

with cache_col2:
    if st.button("ğŸ”„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨"):
        st.experimental_rerun()

with cache_col3:
    cache_info = st.cache_data.cache_info() if hasattr(st.cache_data, 'cache_info') else None
    if cache_info:
        st.caption(f"ìºì‹œ íˆíŠ¸ìœ¨: {cache_info.hit_rate:.1%}")
    else:
        st.caption("ìºì‹œ ì •ë³´ ì—†ìŒ")

# ì‚¬ìš©ì ì„¸ì…˜ ì •ë³´
if st.checkbox("ğŸ‘¤ ì„¸ì…˜ ì •ë³´", help="í˜„ì¬ ì‚¬ìš©ì ì„¸ì…˜ ìƒíƒœ í™•ì¸"):
    session_info = {
        "ì„¸ì…˜_ID": id(st.session_state),
        "ì—…ë¡œë“œëœ_íŒŒì¼": uploaded_file.name if uploaded_file else "ì—†ìŒ",
        "ë§ˆì§€ë§‰_ì—…ë°ì´íŠ¸": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "ì²˜ë¦¬ëœ_ë°ì´í„°_í¬ê¸°": len(base_data) if 'base_data' in locals() and not base_data.empty else 0,
        "í™œì„±_í•„í„°": {
            "ê²€ìƒ‰ì–´": search_query or "ì—†ìŒ",
            "ë‹´ë‹¹ì_í•„í„°": owner_filter or "ì—†ìŒ",
            "Gapë§Œ_í‘œì‹œ": show_only_gap
        }
    }
    st.json(session_info)

# ë§ˆì§€ë§‰ ì •ë¦¬ ë° ìƒíƒœ ì²´í¬
try:
    # ë§ˆì§€ë§‰ ìƒíƒœ ê²€ì¦
    final_status = {
        "íŒŒì¼_ì—…ë¡œë“œ": "ì™„ë£Œ" if uploaded_file else "ëŒ€ê¸°ì¤‘",
        "ë°ì´í„°_ë¡œë“œ": "ì™„ë£Œ" if 'base_data' in locals() and not base_data.empty else "ì‹¤íŒ¨",
        "ì§‘ê³„_ì™„ë£Œ": "ì™„ë£Œ" if 'agg_table' in locals() and not agg_table.empty else "ì‹¤íŒ¨",
        "ê²€ìƒ‰_ê¸°ëŠ¥": "í™œì„±" if 'filtered_table' in locals() else "ë¹„í™œì„±"
    }
    
    logger.info(f"ìµœì¢… ìƒíƒœ: {final_status}")
    
    # ì˜¤ë¥˜ ìƒí™© ì²´í¬
    if uploaded_file and ('base_data' not in locals() or base_data.empty):
        st.error("âš ï¸ íŒŒì¼ì€ ì—…ë¡œë“œë˜ì—ˆìœ¼ë‚˜ ë°ì´í„° ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    if 'agg_table' in locals() and agg_table.empty and uploaded_file:
        st.error("âš ï¸ ì§‘ê³„ í…Œì´ë¸” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
except Exception as e:
    logger.error(f"ìµœì¢… ìƒíƒœ ì²´í¬ ì˜¤ë¥˜: {e}")

# ì„±ëŠ¥ í†µê³„ (ì „ì²´ ì„¸ì…˜)
if 'performance_stats' not in st.session_state:
    st.session_state.performance_stats = {
        'start_time': datetime.now(),
        'file_uploads': 0,
        'searches_performed': 0,
        'matches_computed': 0
    }

# í†µê³„ ì—…ë°ì´íŠ¸
if uploaded_file:
    st.session_state.performance_stats['file_uploads'] += 1

if search_query or owner_filter:
    st.session_state.performance_stats['searches_performed'] += 1

# ìµœì¢… ì•Œë¦¼ ë©”ì‹œì§€
if uploaded_file and 'base_data' in locals() and not base_data.empty:
    session_duration = datetime.now() - st.session_state.performance_stats['start_time']
    
    if len(base_data) > 1000:
        st.success(f"ğŸ‰ ëŒ€ìš©ëŸ‰ ë°ì´í„° ({len(base_data):,}ê±´) ì²˜ë¦¬ ì™„ë£Œ! "
                  f"ì„¸ì…˜ ì‹œê°„: {session_duration.seconds//60}ë¶„ {session_duration.seconds%60}ì´ˆ")
    else:
        st.success(f"âœ… ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ ({len(base_data)}ê±´)")

# ë§ˆì§€ë§‰ ì•ˆë‚´ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
if uploaded_file and 'filtered_table' in locals():
    if len(filtered_table) == 0 and (search_query or owner_filter):
        st.info("ğŸ” **ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.** ìœ„ì˜ 'ê²€ìƒ‰ ë””ë²„ê¹… ì •ë³´'ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ì„¸ìš”.")
    elif not uploaded_file:
        st.info("ğŸ‘ˆ ì‹œì‘í•˜ë ¤ë©´ ì¢Œì¸¡ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        st.success("âœ… ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!")

# ì—ëŸ¬ ë³µêµ¬ ê°€ì´ë“œ
with st.expander("ğŸš¨ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ"):
    st.markdown("""
    ### ğŸ”§ ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ë°©ë²•
    
    **1. ê²€ìƒ‰ì´ ì•ˆ ë  ë•Œ:**
    - 'ê²€ìƒ‰ ë””ë²„ê¹… ì •ë³´ í‘œì‹œ' ì²´í¬ë°•ìŠ¤ë¥¼ í™œì„±í™”í•˜ì—¬ ë¬¸ì œ ì§„ë‹¨
    - ë¶€ë¶„ ê²€ìƒ‰ì–´ ì‚¬ìš© (ì˜ˆ: 'í”„ë¡œì íŠ¸' â†’ 'PJT')
    - íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ê²€ìƒ‰
    
    **2. íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ:**
    - íŒŒì¼ í™•ì¥ì í™•ì¸ (.xlsx, .xlsm, .xls)
    - íŒŒì¼ í¬ê¸° í™•ì¸ (10MB ì´í•˜ ê¶Œì¥)
    - ë‹¤ë¥¸ ë¸Œë¼ìš°ì €ë¡œ ì‹œë„
    
    **3. ë°ì´í„°ê°€ ì´ìƒí•  ë•Œ:**
    - 'ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ'ë¡œ ë°ì´í„° êµ¬ì¡° í™•ì¸
    - ì›ë³¸ ì—‘ì…€ íŒŒì¼ì˜ ì‹œíŠ¸ëª…ê³¼ ì»¬ëŸ¼ëª… í™•ì¸
    - ë°ì´í„° ìºì‹œ ì´ˆê¸°í™” í›„ ì¬ì‹œë„
    
    **4. ì„±ëŠ¥ì´ ëŠë¦´ ë•Œ:**
    - ë©”ëª¨ë¦¬ ì •ë¦¬ ë²„íŠ¼ í´ë¦­
    - ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨
    - ë°ì´í„°ë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• 
    """)

logger.info("Streamlit ì•± ë Œë”ë§ ì™„ë£Œ - ëª¨ë“  ë””ë²„ê¹… ë„êµ¬ í¬í•¨")

# ì„±ëŠ¥ ìµœì í™” íŒ
with st.expander("âš¡ ì„±ëŠ¥ ìµœì í™” íŒ"):
    st.markdown("""
    ### ğŸš€ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê¶Œì¥ì‚¬í•­
    
    **ë°ì´í„° ì¤€ë¹„:**
    - ì—‘ì…€ íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ ê¶Œì¥
    - ë¶ˆí•„ìš”í•œ ì‹œíŠ¸ ì œê±°
    - ë¹ˆ í–‰/ì—´ ì •ë¦¬
    
    **ë§¤ì¹­ ì„¤ì •:**
    - ê¸ˆì•¡ í—ˆìš©ì˜¤ì°¨ë¥¼ ë„ˆë¬´ í¬ê²Œ ì„¤ì •í•˜ì§€ ë§ ê²ƒ
    - ì¼ì ìœˆë„ìš°ëŠ” í•„ìš”í•œ ë§Œí¼ë§Œ ì„¤ì •
    - ì¡°í•© ë§¤ì¹­ ìˆ˜ëŠ” 3ê°œ ì´í•˜ ê¶Œì¥
    
    **ì‚¬ìš©ë²•:**
    - ë¸Œë¼ìš°ì € ìºì‹œ ì •ë¦¬ë¡œ ë©”ëª¨ë¦¬ í™•ë³´
    - í° ë°ì´í„°ëŠ” ê³„ì•½ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¶„ì„
    - ì •ê¸°ì ìœ¼ë¡œ ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨
    """)

# ë„ì›€ë§ ë° FAQ
with st.expander("â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)"):
    st.markdown("""
    ### ğŸ¤” ìì£¼ ë¬»ëŠ” ì§ˆë¬¸
    
    **Q: ì—‘ì…€ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•„ìš”.**
    A: xlsx, xlsm, xls í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³ , íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
    
    **Q: ì»¬ëŸ¼ì„ ì¸ì‹í•˜ì§€ ëª»í•´ìš”.**
    A: ì»¬ëŸ¼ëª…ì´ í•œê¸€/ì˜ë¬¸ìœ¼ë¡œ ëª…í™•íˆ ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. 'ê³„ì•½ë²ˆí˜¸', 'ê¸ˆì•¡', 'ì¼ì' ë“±ì˜ í‘œì¤€ ëª…ì¹­ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    
    **Q: ë§¤ì¹­ ê²°ê³¼ê°€ ì´ìƒí•´ìš”.**
    A: ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì˜ ë§¤ì¹­ ì„¤ì •ì„ ì¡°ì •í•´ë³´ì„¸ìš”. íŠ¹íˆ ê¸ˆì•¡ í—ˆìš©ì˜¤ì°¨ì™€ ì¼ì ìœˆë„ìš°ë¥¼ í™•ì¸í•˜ì„¸ìš”.
    
    **Q: ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì•„ì„œ ëŠë ¤ìš”.**
    A: ê³„ì•½ë³„ë¡œ íŒŒì¼ì„ ë¶„ë¦¬í•˜ê±°ë‚˜, ê¸°ê°„ì„ ë‚˜ëˆ„ì–´ì„œ ë¶„ì„í•´ë³´ì„¸ìš”.
    
    **Q: ì°¨íŠ¸ê°€ í‘œì‹œë˜ì§€ ì•Šì•„ìš”.**
    A: ë‚ ì§œ ë°ì´í„°ê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³ , ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
    """)

# ë²„ì „ ì •ë³´ ë° ì—…ë°ì´íŠ¸ ë¡œê·¸
st.markdown("---")
version_col1, version_col2 = st.columns(2)

with version_col1:
    st.caption("**Version 2.0 - ì™„ì „ ê°œì„ íŒ**")
    st.caption("Last updated: 2025-08-31")

with version_col2:
    st.caption("ğŸ”„ **ì£¼ìš” ê°œì„ ì‚¬í•­:**")
    st.caption("â€¢ ì•ˆì •ì„± í–¥ìƒ â€¢ ì„±ëŠ¥ ìµœì í™” â€¢ UI/UX ê°œì„  â€¢ ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”")

# ìˆ¨ê²¨ì§„ ê³ ê¸‰ ê¸°ëŠ¥ë“¤
if st.secrets.get("debug_mode", False):
    st.markdown("---")
    st.markdown("### ğŸ› ï¸ ê³ ê¸‰ ê°œë°œì ë„êµ¬")
    
    if st.button("ğŸ”„ ìºì‹œ ì´ˆê¸°í™”"):
        st.cache_data.clear()
        st.success("ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.experimental_rerun()
    
    if st.button("ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸"):
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        
        st.info(f"í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_info.rss / 1024 / 1024:.2f} MB")
    
    if not base_data.empty:
        if st.button("ğŸ“ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)"):
            csv_data = base_data.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="í‘œì¤€í™”ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
                data=csv_data,
                file_name=f"standardized_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )

# ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
st.markdown("---")
feedback_col1, feedback_col2 = st.columns(2)

with feedback_col1:
    st.markdown("### ğŸ“ ì‚¬ìš©ì í”¼ë“œë°±")
    user_rating = st.select_slider(
        "ì´ ë„êµ¬ê°€ ì–¼ë§ˆë‚˜ ìœ ìš©í–ˆë‚˜ìš”?",
        options=["ğŸ˜ ë§¤ìš° ë¶ˆë§Œ", "ğŸ˜ ë¶ˆë§Œ", "ğŸ™‚ ë³´í†µ", "ğŸ˜Š ë§Œì¡±", "ğŸ˜ ë§¤ìš° ë§Œì¡±"],
        value="ğŸ™‚ ë³´í†µ"
    )

with feedback_col2:
    feedback_text = st.text_area(
        "ê°œì„  ì‚¬í•­ì´ë‚˜ ì˜ê²¬ì„ ì•Œë ¤ì£¼ì„¸ìš”:",
        placeholder="ë” ë‚˜ì€ ë„êµ¬ê°€ ë  ìˆ˜ ìˆë„ë¡ ì˜ê²¬ì„ ë‚¨ê²¨ì£¼ì„¸ìš”...",
        height=100
    )
    
    if st.button("ğŸ“¤ í”¼ë“œë°± ì „ì†¡"):
        if feedback_text.strip():
            # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ì´ë©”ì¼ë¡œ ì „ì†¡
            logger.info(f"ì‚¬ìš©ì í”¼ë“œë°±: {user_rating} - {feedback_text}")
            st.success("í”¼ë“œë°±ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ™")
        else:
            st.warning("í”¼ë“œë°± ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ìµœì¢… ì•ˆë‚´ ë©”ì‹œì§€
if uploaded_file:
    st.success("âœ… ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ì˜ íƒ­ë“¤ì„ í†µí•´ ìƒì„¸í•œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
else:
    st.info("ğŸ‘ˆ ì‹œì‘í•˜ë ¤ë©´ ì¢Œì¸¡ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# ì—ëŸ¬ ë¡œê¹… ì‹œìŠ¤í…œ (ì‹¤ì œ ìš´ì˜í™˜ê²½ìš©)
try:
    # ì„¸ì…˜ ìƒíƒœì— ì—ëŸ¬ ì¹´ìš´íŠ¸ ì €ì¥
    if 'error_count' not in st.session_state:
        st.session_state.error_count = 0
    
    # 10ë¶„ë§ˆë‹¤ ì—ëŸ¬ ì¹´ìš´íŠ¸ ë¦¬ì…‹
    if 'last_reset' not in st.session_state:
        st.session_state.last_reset = datetime.now()
    
    if (datetime.now() - st.session_state.last_reset).seconds > 600:
        st.session_state.error_count = 0
        st.session_state.last_reset = datetime.now()
        
except Exception as e:
    logger.error(f"ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ì˜¤ë¥˜: {e}")

# ë§ˆì§€ë§‰ ì •ë¦¬ ì‘ì—…
try:
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    if 'base_data' in locals() and len(base_data) > 10000:
        # ëŒ€ìš©ëŸ‰ ë°ì´í„°ì¸ ê²½ìš° ë©”ëª¨ë¦¬ ìµœì í™” ìˆ˜í–‰
        import gc
        gc.collect()
        
except Exception as e:
    logger.error(f"ì •ë¦¬ ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")

# ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ ë©”ì‹œì§€ (ê°œë°œììš©)
logger.info("Streamlit ì•± ë Œë”ë§ ì™„ë£Œ")
