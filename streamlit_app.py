
# -*- coding: utf-8 -*-
from __future__ import annotations

import io
import json
import math
import os
import re
import hashlib
import zipfile
from calendar import monthrange
from difflib import SequenceMatcher
from typing import Dict, Optional, Tuple, List

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st

st.set_page_config(page_title="ì„ ìˆ˜Â·ì„ ê¸‰ê¸ˆ ë§¤ì¹­ & ì˜ì—… ëŒ€ì‹œë³´ë“œ", layout="wide", page_icon="ğŸ“Š")
DEFAULT_EXCEL_PATH = "./2025.07ì›”ë§ ì„ ìˆ˜ì„ ê¸‰ê¸ˆ í˜„í™©_20250811.xlsx"
HISTORY_PATH = "./_history_snapshot.jsonl"

# -----------------------------
# ìœ í‹¸
# -----------------------------
def norm_col(c: str) -> str:
    if not isinstance(c, str):
        return c
    return (
        c.replace("\\n", "").replace("\n", "").replace("\r", "").replace(" ", "").strip()
    )

def normalize_text(s: Optional[str]) -> str:
    if s is None or (isinstance(s, float) and math.isnan(s)):
        return ""
    return "".join(ch for ch in str(s).upper().strip())

def text_sim(a: Optional[str], b: Optional[str]) -> float:
    a, b = normalize_text(a), normalize_text(b)
    if not a or not b:
        return 0.0
    return SequenceMatcher(None, a, b).ratio()

def to_number(x) -> Optional[float]:
    try:
        if pd.isna(x):
            return None
        if isinstance(x, str):
            x = x.replace(",", "").replace(" ", "")
            if re.search(r"[^\d.\-+]", x):
                return None
        v = float(x)
        if math.isfinite(v):
            return v
        return None
    except Exception:
        return None

def choose_amount_row(row: pd.Series) -> Optional[float]:
    for key in ["ì „í‘œí†µí™”ì•¡", "í˜„ì§€í†µí™”ì•¡"]:
        if key in row.index:
            v = to_number(row[key])
            if v is not None:
                return v
    return None

def to_date(x) -> Optional[pd.Timestamp]:
    try:
        if pd.isna(x):
            return None
        return pd.to_datetime(x)
    except Exception:
        return None

def ensure_keycols(df: pd.DataFrame) -> pd.DataFrame:
    mapping = {
        "ì •ì‚°\nì„ ìˆ˜ê¸ˆ\nê³ ìœ ë²ˆí˜¸": "ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸",
        "ì •ì‚°ì—¬ë¶€\n(O/X)": "ì •ì‚°ì—¬ë¶€",
        "ê³ ê°ëª…\n(ë“œë¡­ë‹¤ìš´)": "ê³ ê°ëª…",
        "íšŒìˆ˜ëª©í‘œì¼ì •\n(YY/MM)": "ì •ì‚°ëª©í‘œì¼ì •(YY/MM)",
        "ê²½ê³¼ê¸°ê°„\n(ê°œì›”)": "ê²½ê³¼ê¸°ê°„(ê°œì›”)",
        "ë‹´ë‹¹íŒ€\n(ë³€ê²½ì‹œ)": "ë‹´ë‹¹íŒ€_ë³€ê²½ì‹œ",
        "ì˜ì—…ë‹´ë‹¹\n(ë³€ê²½ì‹œ)": "ì˜ì—…ë‹´ë‹¹_ë³€ê²½ì‹œ",
        "ì—°ë½ì´ë ¥": "ì—°ë½ì´ë ¥",
        "ì—°ë½ ì´ë ¥": "ì—°ë½ì´ë ¥",
        "ì§„í–‰\ní˜„í™©": "ì§„í–‰í˜„í™©",
        "ì§„í–‰ í˜„í™©": "ì§„í–‰í˜„í™©",
        "ì •ì‚°ì§„í–‰í˜„í™©": "ì •ì‚°ì§„í–‰í˜„í™©",
    }
    for old, new in mapping.items():
        if old in df.columns and new not in df.columns:
            df.rename(columns={old: new}, inplace=True)

    if "ì˜ì—…ë‹´ë‹¹" in df.columns:
        df["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"] = df["ì˜ì—…ë‹´ë‹¹"]
    elif "ì˜ì—…ë‹´ë‹¹_ë³€ê²½ì‹œ" in df.columns:
        df["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"] = df["ì˜ì—…ë‹´ë‹¹_ë³€ê²½ì‹œ"]
    else:
        df["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"] = None

    for c in ["ì§„í–‰í˜„í™©", "ì—°ë½ì´ë ¥", "ì •ì‚°ì§„í–‰í˜„í™©"]:
        if c not in df.columns:
            df[c] = None

    return df

def parse_due_yy_mm(val) -> Optional[pd.Timestamp]:
    if val is None or (isinstance(val, float) and math.isnan(val)):
        return None
    s = str(val).strip()
    if not s:
        return None
    m = re.match(r"^\s*(\d{2})[./\- ]?(\d{1,2})\s*$", s)
    if not m:
        return None
    yy = int(m.group(1)); mm = int(m.group(2))
    year = 2000 + yy if yy <= 79 else 1900 + yy
    mm = max(1, min(12, mm))
    last_day = monthrange(year, mm)[1]
    return pd.Timestamp(year=year, month=mm, day=last_day)

SETTLED_FLAG_TRUE = {"O","o","Y","y","1","True","TRUE","true"}
SETTLED_FLAG_FALSE = {"X","x","N","n","0","False","FALSE","false"}
POSITIVE_PATTERNS = [
    r"(?<!ë¯¸)ì™„ë£Œ(?![ê°€-í£])",  # 'ë¯¸ì™„ë£Œ' ì œì™¸
    r"ì…ê¸ˆ\s*ì™„ë£Œ",
    r"ìˆ˜ë‚©\s*ì™„ë£Œ",
    r"\bsettled\b|\bcleared\b|\bclosed\b"
]
NEGATIVE_HINTS = [
    "ë¯¸ì™„ë£Œ","ë¯¸ì •ì‚°","ë¯¸ì…ê¸ˆ","ì—°ì²´","ë³´ë¥˜","ëŒ€ê¸°","ì˜ˆì •","ì§„í–‰","ì§„í–‰ì¤‘","í˜‘ì˜","ê²€í† ","ìš”ì²­","í™•ì¸ì¤‘"
]

def looks_settled(row: pd.Series) -> bool:
    v1 = str(row.get("ì •ì‚°ì—¬ë¶€", "")).strip()
    if v1 in SETTLED_FLAG_TRUE:
        return True
    if v1 in SETTLED_FLAG_FALSE:
        return False

    v2 = str(row.get("ì •ì‚°ì§„í–‰í˜„í™©", "")).strip().lower()
    v3 = str(row.get("ì§„í–‰í˜„í™©", "")).strip().lower()
    t = f"{v2} {v3}".strip()

    if any(h in t for h in [h.lower() for h in NEGATIVE_HINTS]):
        return False
    for pat in POSITIVE_PATTERNS:
        if re.search(pat, t):
            return True
    return False

def add_common_fields(df: pd.DataFrame) -> pd.DataFrame:
    if "ê¸ˆì•¡" not in df.columns:
        df["ê¸ˆì•¡"] = df.apply(choose_amount_row, axis=1)
    if "ì „ê¸°ì¼" in df.columns and "ì „ê¸°ì¼_parsed" not in df.columns:
        df["ì „ê¸°ì¼_parsed"] = pd.to_datetime(df["ì „ê¸°ì¼"], errors="coerce")
    if "íšŒìˆ˜ëª©í‘œì¼ì" in df.columns:
        df["íšŒìˆ˜ëª©í‘œì¼ì"] = pd.to_datetime(df["íšŒìˆ˜ëª©í‘œì¼ì"], errors="coerce")
    elif "ì •ì‚°ëª©í‘œì¼ì •(YY/MM)" in df.columns:
        df["íšŒìˆ˜ëª©í‘œì¼ì"] = df["ì •ì‚°ëª©í‘œì¼ì •(YY/MM)"].apply(parse_due_yy_mm)
    else:
        df["íšŒìˆ˜ëª©í‘œì¼ì"] = pd.NaT

    df["is_settled"] = df.apply(looks_settled, axis=1)
    df["ê¸ˆì•¡_num"] = df["ê¸ˆì•¡"].apply(to_number)
    for c in ["ì§„í–‰í˜„í™©","ì—°ë½ì´ë ¥","ì •ì‚°ì§„í–‰í˜„í™©"]:
        if c not in df.columns: df[c] = None
    return df

@st.cache_data(show_spinner=False)
def load_excel(excel_bytes_or_path) -> Dict[str, pd.DataFrame]:
    if excel_bytes_or_path is None:
        return {}
    xls = pd.ExcelFile(excel_bytes_or_path)
    sheets = {}
    for s in xls.sheet_names:
        df = pd.read_excel(xls, sheet_name=s)
        df.columns = [norm_col(c) for c in df.columns]
        df = df.dropna(how="all")
        df = ensure_keycols(df)
        df = add_common_fields(df)
        sheets[s] = df
    return sheets

def find_sheet(sheets: Dict[str, pd.DataFrame], target: str) -> Optional[str]:
    tgt = normalize_text(target)
    for name in sheets.keys():
        if normalize_text(name) == tgt:
            return name
    for name in sheets.keys():
        if tgt in normalize_text(name):
            return name
    return None

# -----------------------------
# ë§¤ì¹­ ì ìˆ˜
# -----------------------------
def calc_match_score(sunsu: pd.Series, seongeup: pd.Series, date_half_life_days: int = 90) -> Tuple[float, Dict[str, float]]:
    weights = {"linked_id": 60.0, "contract": 20.0, "name": 10.0, "date": 5.0, "text": 5.0, "amount": 10.0}
    def get(row: pd.Series, key: str) -> Optional[str]:
        return row.get(key) if key in row.index else None

    linked = 0.0
    seon_link = get(seongeup, "ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸") or get(seongeup, "ì •ì‚°\nì„ ìˆ˜ê¸ˆ\nê³ ìœ ë²ˆí˜¸")
    sun_id = get(sunsu, "ê³ ìœ ë„˜ë²„")
    if seon_link and sun_id and str(seon_link).strip() == str(sun_id).strip():
        linked = 1.0

    contract_equal = 0.0
    if get(sunsu, "ê³„ì•½ë²ˆí˜¸") and get(seongeup, "ê³„ì•½ë²ˆí˜¸"):
        if str(get(sunsu, "ê³„ì•½ë²ˆí˜¸")).strip() == str(get(seongeup, "ê³„ì•½ë²ˆí˜¸")).strip():
            contract_equal = 1.0

    name_sim = text_sim(get(sunsu, "ì—…ì²´ëª…"), get(seongeup, "ì—…ì²´ëª…"))

    d1 = to_date(get(sunsu, "ì „ê¸°ì¼"))
    d2 = to_date(get(seongeup, "ì „ê¸°ì¼"))
    date_score = 0.0
    if d1 is not None and d2 is not None:
        dd = abs((d1 - d2).days)
        date_score = 0.5 ** (dd / float(max(date_half_life_days, 1)))

    text_contains = 0.0
    if get(seongeup, "í…ìŠ¤íŠ¸") and get(sunsu, "ê³„ì•½ë²ˆí˜¸"):
        if str(get(sunsu, "ê³„ì•½ë²ˆí˜¸")).strip() in str(get(seongeup, "í…ìŠ¤íŠ¸")):
            text_contains = 1.0

    amt_sun = sunsu.get("ê¸ˆì•¡_num")
    amt_seon = seongeup.get("ê¸ˆì•¡_num")
    amount_score = 0.0
    if (amt_sun is not None) and (amt_seon is not None) and (amt_sun != 0):
        diff = abs(amt_sun - amt_seon)
        amount_score = max(0.0, 1.0 - (diff / abs(amt_sun)))

    parts = {
        "linked_id": linked * weights["linked_id"],
        "contract": contract_equal * weights["contract"],
        "name": name_sim * weights["name"],
        "date": date_score * weights["date"],
        "text": text_contains * weights["text"],
        "amount": amount_score * weights["amount"],
    }
    total = sum(parts.values())
    return total, parts

# -----------------------------
# ê³µí†µ í‘œí˜„: ê¸ˆì•¡ í¬ë§· (ì •ìˆ˜ ì›, ì½¤ë§ˆ) - ë¬¸ìì—´ ë Œë”ë§ë¡œ ì˜¤ë¥˜ íšŒí”¼
# -----------------------------
def _money_like(col: str) -> bool:
    return ("ê¸ˆì•¡" in col) or ("í•©ê³„" in col) or (col in ["ê¸ˆì•¡_num", "ê¸ˆì•¡"])

def _fmt_won(v):
    if pd.isna(v):
        return ""
    try:
        return f"{int(round(float(v))):,}"
    except Exception:
        return str(v)

def display_df(df: pd.DataFrame, height: int = 420):
    df2 = df.copy()
    money_cols = [c for c in df2.columns if _money_like(c)]
    for c in money_cols:
        df2[c] = df2[c].apply(_fmt_won)
    st.dataframe(df2, width='stretch', height=height)

# -----------------------------
# ë°ì´í„° ë¡œë“œ & ê¶Œí•œ
# -----------------------------
st.sidebar.header("ë°ì´í„°")
excel_file = st.sidebar.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"], accept_multiple_files=False)

sheets = {}
try:
    if excel_file is not None:
        sheets = load_excel(excel_file)
    else:
        with open(DEFAULT_EXCEL_PATH, "rb") as f:
            sheets = load_excel(f)
            st.sidebar.info("ê¸°ë³¸ ê²½ë¡œì—ì„œ ì—‘ì…€ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
except Exception:
    st.sidebar.warning("ì—‘ì…€ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜, ë¦¬í¬ì§€í† ë¦¬ì— ì—‘ì…€ì„ í¬í•¨ì‹œì¼œ ì£¼ì„¸ìš”.")

if not sheets:
    st.info("ë°ì´í„°ê°€ ì—†ì–´ì„œ ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤. ì™¼ìª½ì—ì„œ ì—‘ì…€ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

s_sunsu = find_sheet(sheets, "ì„ ìˆ˜ê¸ˆ")
s_seon = find_sheet(sheets, "ì„ ê¸‰ê¸ˆ")
if s_sunsu is None or s_seon is None:
    st.error("ì‹œíŠ¸ ì´ë¦„ 'ì„ ìˆ˜ê¸ˆ'ê³¼ 'ì„ ê¸‰ê¸ˆ'ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì—‘ì…€ ì‹œíŠ¸ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

df_sunsu = sheets[s_sunsu].copy()
df_seon = sheets[s_seon].copy()

# ê¶Œí•œë·°
st.sidebar.header("ê¶Œí•œ/ë‹´ë‹¹ì")
owners_all = sorted(set([x for x in df_sunsu["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"].dropna().unique().tolist() + df_seon["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"].dropna().unique().tolist()]))
my_only = st.sidebar.checkbox("ë³¸ì¸ ê±´ë§Œ ë³´ê¸°", value=False)
my_name = st.sidebar.selectbox("ë‚´ ë‹´ë‹¹ìëª…", options=["(ì„ íƒ)"] + owners_all, index=0)

def apply_my_view(df: pd.DataFrame) -> pd.DataFrame:
    if my_only and my_name and my_name != "(ì„ íƒ)":
        return df[df["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"] == my_name].copy()
    return df

df_sunsu = apply_my_view(df_sunsu)
df_seon = apply_my_view(df_seon)

# ê³µí†µ í•„í„°
st.sidebar.header("ê³µí†µ í•„í„°")
owner_multi = st.sidebar.multiselect("ì˜ì—…ë‹´ë‹¹ ì„ íƒ(ë³µìˆ˜)", options=owners_all, default=[])
only_unsettled = st.sidebar.checkbox("ë¯¸ì •ì‚°ë§Œ ë³´ê¸°", value=False)
only_overdue = st.sidebar.checkbox("ì—°ì²´ë§Œ ë³´ê¸°(í˜„ì¬ ê¸°ì¤€)", value=False)

def apply_owner_status_filter(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    if owner_multi:
        out = out[out["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"].isin(owner_multi)]
    if only_unsettled:
        out = out[~out["is_settled"]]
    now = pd.Timestamp.now()
    if only_overdue:
        due = out["íšŒìˆ˜ëª©í‘œì¼ì"] if "íšŒìˆ˜ëª©í‘œì¼ì" in out.columns else pd.Series(pd.NaT, index=out.index)
        out = out[(~out["is_settled"]) & (due.notna()) & (due < now)]
    return out

df_sunsu_f = apply_owner_status_filter(df_sunsu)
df_seon_f = apply_owner_status_filter(df_seon)

# -----------------------------
# ìƒíƒœ ì •ì˜ & íŒŒì´í”„ë¼ì¸
# -----------------------------
def enrich_status_pipeline(df: pd.DataFrame) -> pd.DataFrame:
    base = df.copy()
    now = pd.Timestamp.now()
    this_month = now.to_period("M")

    base["ìƒíƒœ"] = "ì •ë³´ì—†ìŒ"
    base.loc[base["is_settled"] == True, "ìƒíƒœ"] = "ì²˜ë¦¬ì™„ë£Œ"
    due = base["íšŒìˆ˜ëª©í‘œì¼ì"] if "íšŒìˆ˜ëª©í‘œì¼ì" in base.columns else pd.Series(pd.NaT, index=base.index)
    cond_un = (base["is_settled"] == False)
    has_due = due.notna()

    base.loc[cond_un & has_due & (due < now), "ìƒíƒœ"] = "ì—°ì²´"
    base.loc[cond_un & has_due & (due.dt.to_period("M") == this_month), "ìƒíƒœ"] = "ë‹¹ì›”ì˜ˆì •"
    base.loc[cond_un & (~has_due), "ìƒíƒœ"] = "ê¸°í•œë¯¸ì„¤ì •"
    base.loc[cond_un & has_due & (due.dt.to_period("M") > this_month), "ìƒíƒœ"] = "í–¥í›„ì˜ˆì •"

    def map_progress(*values: str) -> Optional[str]:
        t = " ".join([str(x).strip().lower() for x in values if isinstance(x, str)])
        if not t: return None
        if any(k in t for k in ["íšŒìˆ˜ì¤‘", "ìˆ˜ê¸ˆì¤‘", "ì§•ìˆ˜ì¤‘", "collection"]): return "íšŒìˆ˜ì¤‘"
        if any(k in t for k in ["í˜‘ì˜", "ë…¼ì˜", "ì»¨íŒ", "ì¡°ìœ¨"]): return "í˜‘ì˜ì¤‘"
        if any(k in t for k in ["ë³´ë¥˜", "hold", "ëŒ€ê¸°"]): return "ë³´ë¥˜"
        if any(k in t for k in ["ì†Œì†¡", "ë¶„ìŸ", "ë²•ë¬´"]): return "ë¶„ìŸ/ì†Œì†¡"
        if any(k in t for k in ["ë¬´ì‘ë‹µ", "ì—°ë½ë‘ì ˆ"]): return "ë¬´ì‘ë‹µ"
        if any(re.search(p, t) for p in POSITIVE_PATTERNS) and not any(h in t for h in [h.lower() for h in NEGATIVE_HINTS]): return "ì™„ë£Œ"
        return None

    if "ì§„í–‰í˜„í™©" not in base.columns: base["ì§„í–‰í˜„í™©"] = None
    if "ì •ì‚°ì§„í–‰í˜„í™©" not in base.columns: base["ì •ì‚°ì§„í–‰í˜„í™©"] = None
    base["ì„¸ë¶€ìƒíƒœ"] = base.apply(lambda r: map_progress(r.get("ì§„í–‰í˜„í™©"), r.get("ì •ì‚°ì§„í–‰í˜„í™©")), axis=1)
    base["ìƒíƒœ(ì„¸ë¶€)"] = base["ìƒíƒœ"]
    mask = base["ì„¸ë¶€ìƒíƒœ"].notna()
    base.loc[mask, "ìƒíƒœ(ì„¸ë¶€)"] = base.loc[mask, "ìƒíƒœ"] + "-" + base.loc[mask, "ì„¸ë¶€ìƒíƒœ"]

    stage = pd.Series("", index=base.index, dtype="object")
    if "íšŒìˆ˜ëª©í‘œì¼ì" in base.columns:
        ddays = (due.dt.normalize() - now.normalize()).dt.days
        stage[(base["ìƒíƒœ"] == "ë‹¹ì›”ì˜ˆì •") & (ddays <= -1)] = "ì§€ì—°"
        stage[(base["ìƒíƒœ"] == "ë‹¹ì›”ì˜ˆì •") & (ddays == 0)] = "ë‹¹ì¼"
        stage[(base["ìƒíƒœ"] == "ë‹¹ì›”ì˜ˆì •") & (ddays.between(1, 3))] = "D-3"
        stage[(base["ìƒíƒœ"] == "ë‹¹ì›”ì˜ˆì •") & (ddays.between(4, 7))] = "D-7"
        stage[(base["ìƒíƒœ"] == "ë‹¹ì›”ì˜ˆì •") & (ddays >= 8)] = "ë‹¹ì›”(8ì¼+)"
    base["íŒŒì´í”„ë¼ì¸"] = stage.where(stage != "", other=None)

    if "ì—°ë½ì´ë ¥" not in base.columns: base["ì—°ë½ì´ë ¥"] = None

    return base

sunsu_s = enrich_status_pipeline(df_sunsu_f)
seon_s = enrich_status_pipeline(df_seon_f)

# -----------------------------
# AI íˆìŠ¤í† ë¦¬ ì¶”ì  (ê°„ë‹¨)
# -----------------------------
KEY_COLS_FOR_HISTORY = ["êµ¬ë¶„","í‚¤","ì˜ì—…ë‹´ë‹¹_í‘œì¤€","ì—…ì²´ëª…","ê³„ì•½ë²ˆí˜¸","ê³ ìœ ë„˜ë²„","ì „ê¸°ì¼_parsed","íšŒìˆ˜ëª©í‘œì¼ì","ìƒíƒœ","ìƒíƒœ(ì„¸ë¶€)","íŒŒì´í”„ë¼ì¸","ì •ì‚°ì§„í–‰í˜„í™©","ì •ì‚°ì—¬ë¶€","ì—°ë½ì´ë ¥","ë¹„ê³ ","ê¸ˆì•¡_num"]

def make_key(row: pd.Series) -> str:
    gid = str(row.get("ê³ ìœ ë„˜ë²„", "")).strip()
    if gid:
        return gid
    parts = [
        str(row.get("ì „í‘œë²ˆí˜¸","")).strip(),
        str(row.get("ê³„ì•½ë²ˆí˜¸","")).strip(),
        str(row.get("ì—…ì²´ëª…","")).strip(),
        str(row.get("ì „ê¸°ì¼_parsed","")).strip()
    ]
    base = "|".join(parts)
    return hashlib.sha1(base.encode("utf-8")).hexdigest()[:12]

def build_current_snapshot() -> pd.DataFrame:
    a = sunsu_s.assign(êµ¬ë¶„="ì„ ìˆ˜ê¸ˆ").copy()
    b = seon_s.assign(êµ¬ë¶„="ì„ ê¸‰ê¸ˆ").copy()
    allv = pd.concat([a, b], ignore_index=True, sort=False)
    allv["í‚¤"] = allv.apply(make_key, axis=1)
    return allv

def load_last_snapshot() -> Optional[pd.DataFrame]:
    if not os.path.exists(HISTORY_PATH):
        return None
    try:
        records = [json.loads(line) for line in open(HISTORY_PATH, "r", encoding="utf-8")]
        if not records:
            return None
        last = records[-1]
        return pd.DataFrame(last["data"])
    except Exception:
        return None

def save_snapshot(df: pd.DataFrame):
    rec = {
        "ts": pd.Timestamp.now().isoformat(),
        "data": df[KEY_COLS_FOR_HISTORY].fillna("").astype(str).to_dict(orient="records"),
    }
    with open(HISTORY_PATH, "a", encoding="utf-8") as f:
        f.write(json.dumps(rec, ensure_ascii=False) + "\n")

def diff_snapshots(prev: Optional[pd.DataFrame], curr: pd.DataFrame) -> pd.DataFrame:
    if prev is None or prev.empty:
        return pd.DataFrame(columns=["í‚¤","ë³€ê²½í•­ëª©","ì´ì „ê°’","í˜„ì¬ê°’","êµ¬ë¶„","ì—…ì²´ëª…","ê³„ì•½ë²ˆí˜¸","ì˜ì—…ë‹´ë‹¹_í‘œì¤€","ë³€ê²½ì‹œê°"])
    prev_i = prev.set_index("í‚¤")
    curr_i = curr.set_index("í‚¤")
    changed_rows = []
    common_keys = set(prev_i.index).intersection(set(curr_i.index))
    cols_to_check = [c for c in KEY_COLS_FOR_HISTORY if c not in ["í‚¤"]]
    for k in common_keys:
        p = prev_i.loc[k]; c = curr_i.loc[k]
        for col in cols_to_check:
            pv = str(p.get(col, "")); cv = str(c.get(col, ""))
            if pv != cv:
                changed_rows.append({
                    "í‚¤": k, "ë³€ê²½í•­ëª©": col, "ì´ì „ê°’": pv, "í˜„ì¬ê°’": cv,
                    "êµ¬ë¶„": c.get("êµ¬ë¶„",""), "ì—…ì²´ëª…": c.get("ì—…ì²´ëª…",""),
                    "ê³„ì•½ë²ˆí˜¸": c.get("ê³„ì•½ë²ˆí˜¸",""), "ì˜ì—…ë‹´ë‹¹_í‘œì¤€": c.get("ì˜ì—…ë‹´ë‹¹_í‘œì¤€",""),
                    "ë³€ê²½ì‹œê°": pd.Timestamp.now()
                })
    return pd.DataFrame(changed_rows)

# -----------------------------
# íƒ­
# -----------------------------
tab0, tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
    "ğŸ‘¤ ì˜ì—… ëŒ€ì‹œë³´ë“œ", "ğŸ” ë§¤ì¹­ ì¡°íšŒ", "âš™ï¸ ì¼ê´„ ë§¤ì¹­", "ğŸ“Š ìš”ì•½ ëŒ€ì‹œë³´ë“œ",
    "ğŸ§­ ê³ ê¸‰ ê²€ìƒ‰", "ğŸ—‚ 3ë‹¨ ê·¸ë¦¬ë“œ", "ğŸ—“ ì£¼ê°„ ê³„íší‘œ", "ğŸ“œ íˆìŠ¤í† ë¦¬"
])

# -----------------------------
# ğŸ‘¤ ì˜ì—… ëŒ€ì‹œë³´ë“œ
# -----------------------------
with tab0:
    st.subheader("ì˜ì—… ë‹´ë‹¹ì ê´€ì  KPI & ìƒíƒœ ë³´ë“œ (í˜„ì¬ ì‹œì  ê¸°ì¤€)")
    now = pd.Timestamp.now()
    sm = pd.Timestamp(now.year, now.month, 1)

    def kpi_block(title: str, df: pd.DataFrame):
        if df.empty:
            st.info(f"{title}: ë°ì´í„° ì—†ìŒ")
            return
        due = df["íšŒìˆ˜ëª©í‘œì¼ì"] if "íšŒìˆ˜ëª©í‘œì¼ì" in df.columns else pd.Series(pd.NaT, index=df.index)
        total = len(df)
        done = int(df["is_settled"].sum())
        overdue = int(((~df["is_settled"]) & due.notna() & (due < now)).sum())
        due_this = int(((~df["is_settled"]) & due.notna() & (due.dt.to_period("M") == sm.to_period("M"))).sum())
        amt_un = df.loc[~df["is_settled"], "ê¸ˆì•¡_num"].sum(skipna=True)
        cols = st.columns(5)
        with cols[0]: st.metric(f"{title} ê±´ìˆ˜", f"{total:,}")
        with cols[1]: st.metric("ì²˜ë¦¬ì™„ë£Œ", f"{done:,}")
        with cols[2]: st.metric("ì—°ì²´", f"{overdue:,}")
        with cols[3]: st.metric("ë‹¹ì›”ì˜ˆì •", f"{due_this:,}")
        with cols[4]: st.metric("ë¯¸ì •ì‚°ê¸ˆì•¡", f"{amt_un:,.0f}" if pd.notna(amt_un) else "-")

    st.markdown("### ì„ ìˆ˜ê¸ˆ"); kpi_block("ì„ ìˆ˜ê¸ˆ", sunsu_s)
    st.markdown("### ì„ ê¸‰ê¸ˆ"); kpi_block("ì„ ê¸‰ê¸ˆ", seon_s)

    def status_chart(df: pd.DataFrame, title: str):
        if df.empty: st.info(f"{title}: ë°ì´í„° ì—†ìŒ"); return
        agg = df.dropna(subset=["ê¸ˆì•¡_num"]).groupby("ìƒíƒœ")["ê¸ˆì•¡_num"].sum().reset_index()
        chart = alt.Chart(agg).mark_bar().encode(x="ìƒíƒœ:N", y=alt.Y("ê¸ˆì•¡_num:Q", title="ê¸ˆì•¡ í•©ê³„")).properties(height=280, title=f"{title} - ìƒíƒœë³„ ê¸ˆì•¡")
        st.altair_chart(chart, use_container_width=True)
        display_df(agg.rename(columns={"ê¸ˆì•¡_num": "ê¸ˆì•¡í•©ê³„"}), height=240)

    c1, c2 = st.columns(2)
    with c1: status_chart(sunsu_s, "ì„ ìˆ˜ê¸ˆ")
    with c2: status_chart(seon_s, "ì„ ê¸‰ê¸ˆ")

# -----------------------------
# ğŸ” ë§¤ì¹­ ì¡°íšŒ
# -----------------------------
with tab1:
    st.subheader("íŠ¹ì • ì„ ìˆ˜ê¸ˆê³¼ ë§¤ì¹­ë˜ëŠ” ì„ ê¸‰ê¸ˆ í›„ë³´ ì¡°íšŒ")
    date_half_life_days = st.slider("ì¼ì ê·¼ì ‘ë„ ì ˆë°˜ê°ì‡ ì¼(ì¼)", 15, 180, 90, 15, key="m_dhl")
    score_threshold = st.slider("í›„ë³´ í‘œì‹œ ìµœì†Œì ìˆ˜", 0, 100, 40, 5, key="m_th")
    if df_sunsu_f.empty or df_seon_f.empty:
        st.warning("í•„í„° ì ìš© í›„ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°” í•„í„°ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
    else:
        def sunsu_label(row: pd.Series) -> str:
            gid = str(row.get("ê³ ìœ ë„˜ë²„", ""))
            comp = str(row.get("ì—…ì²´ëª…", ""))
            contract = str(row.get("ê³„ì•½ë²ˆí˜¸", ""))
            datev = row.get("ì „ê¸°ì¼_parsed", row.get("ì „ê¸°ì¼", ""))
            amt = row.get("ê¸ˆì•¡_num", None)
            amt_str = f"{amt:,.0f}" if isinstance(amt, (int, float, np.number)) and not pd.isna(amt) else "-"
            dstr = datev.strftime("%Y-%m-%d") if isinstance(datev, pd.Timestamp) else (str(datev) if datev is not None else "")
            return f"[{gid}] {comp} | ê³„ì•½:{contract} | ì¼ì:{dstr} | ê¸ˆì•¡:{amt_str}"

        options = df_sunsu_f.index.tolist()
        selectable = [(i, sunsu_label(df_sunsu_f.loc[i])) for i in options]
        selected_idx = st.selectbox("ì„ ìˆ˜ê¸ˆ ì„ íƒ", options=[i for i, _ in selectable], format_func=lambda i: dict(selectable)[i])

        if selected_idx is not None:
            target_row = df_sunsu_f.loc[selected_idx]
            scores: List[dict] = []
            for i, row in df_seon_f.iterrows():
                total, parts = calc_match_score(target_row, row, date_half_life_days=date_half_life_days)
                if total >= score_threshold:
                    scores.append({
                        "ì„ ê¸‰_index": i, "ì´ì ": round(total, 2),
                        **{f"ì ìˆ˜:{k}": round(v, 2) for k, v in parts.items()},
                        "ê³„ì•½ë²ˆí˜¸": row.get("ê³„ì•½ë²ˆí˜¸"), "ì—…ì²´ëª…": row.get("ì—…ì²´ëª…"),
                        "ì „ê¸°ì¼": row.get("ì „ê¸°ì¼_parsed", row.get("ì „ê¸°ì¼")), "ê¸ˆì•¡": row.get("ê¸ˆì•¡_num"),
                        "ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸": row.get("ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸"), "í…ìŠ¤íŠ¸": row.get("í…ìŠ¤íŠ¸"),
                        "ê³ ìœ ë„˜ë²„": row.get("ê³ ìœ ë„˜ë²„"), "ì˜ì—…ë‹´ë‹¹": row.get("ì˜ì—…ë‹´ë‹¹_í‘œì¤€"),
                    })
            if not scores:
                st.info("í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ì ìˆ˜ ì„ê³„ê°’ ë˜ëŠ” í•„í„°ë¥¼ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
            else:
                cand_df = pd.DataFrame(scores).sort_values(by="ì´ì ", ascending=False).reset_index(drop=True)
                display_df(cand_df, height=430)

# -----------------------------
# âš™ï¸ ì¼ê´„ ë§¤ì¹­
# -----------------------------
with tab2:
    st.subheader("ì¼ê´„ ë§¤ì¹­ ì œì•ˆ(Top-1)")
    score_threshold2 = st.slider("í›„ë³´ í‘œì‹œ ìµœì†Œì ìˆ˜", 0, 100, 40, 5, key="b_th")
    limit = st.number_input("ëŒ€ìƒ ì„ ìˆ˜ê¸ˆ ìˆ˜", min_value=10, max_value=max(10, len(df_sunsu_f) if len(df_sunsu_f)>0 else 10), value=min(200, len(df_sunsu_f) if len(df_sunsu_f)>0 else 10), step=10)
    if df_sunsu_f.empty or df_seon_f.empty:
        st.info("ë°ì´í„°ê°€ ë¹„ì–´ ìˆì–´ ì¼ê´„ ì œì•ˆì„ ìƒëµí•©ë‹ˆë‹¤.")
    else:
        rows = []
        for si, srow in df_sunsu_f.head(int(limit)).iterrows():
            best_score = -1.0; best_idx = None
            for ei, erow in df_seon_f.iterrows():
                total, _ = calc_match_score(srow, erow, date_half_life_days=90)
                if total > best_score:
                    best_score = total; best_idx = ei
            if best_idx is not None and best_score >= score_threshold2:
                erow = df_seon_f.loc[best_idx]
                rows.append({
                    "ì„ ìˆ˜_index": si, "ì„ ê¸‰_index": best_idx, "ì´ì ": round(best_score, 2),
                    "ì„ ìˆ˜_ê³ ìœ ë„˜ë²„": srow.get("ê³ ìœ ë„˜ë²„"), "ì„ ìˆ˜_ê³„ì•½ë²ˆí˜¸": srow.get("ê³„ì•½ë²ˆí˜¸"),
                    "ì„ ìˆ˜_ì—…ì²´ëª…": srow.get("ì—…ì²´ëª…"), "ì„ ìˆ˜_ì „ê¸°ì¼": srow.get("ì „ê¸°ì¼_parsed", srow.get("ì „ê¸°ì¼")),
                    "ì„ ìˆ˜_ê¸ˆì•¡": srow.get("ê¸ˆì•¡_num"),
                    "ì„ ê¸‰_ê³ ìœ ë„˜ë²„": erow.get("ê³ ìœ ë„˜ë²„"), "ì„ ê¸‰_ê³„ì•½ë²ˆí˜¸": erow.get("ê³„ì•½ë²ˆí˜¸"),
                    "ì„ ê¸‰_ì—…ì²´ëª…": erow.get("ì—…ì²´ëª…"), "ì„ ê¸‰_ì „ê¸°ì¼": erow.get("ì „ê¸°ì¼_parsed", erow.get("ì „ê¸°ì¼")),
                    "ì„ ê¸‰_ê¸ˆì•¡": erow.get("ê¸ˆì•¡_num"),
                    "ì„ ê¸‰_ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸": erow.get("ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸"),
                    "ì˜ì—…ë‹´ë‹¹": srow.get("ì˜ì—…ë‹´ë‹¹_í‘œì¤€")
                })
        if not rows:
            st.info("ì œì•ˆ ê°€ëŠ¥í•œ ë§¤ì¹­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            dfb = pd.DataFrame(rows).sort_values(by="ì´ì ", ascending=False).reset_index(drop=True)
            display_df(dfb, height=450)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", dfb.to_csv(index=False).encode("utf-8-sig"), file_name="batch_match_suggestions.csv", mime="text/csv")

# -----------------------------
# ğŸ“Š ìš”ì•½ ëŒ€ì‹œë³´ë“œ
# -----------------------------
with tab3:
    st.subheader("ìš”ì•½ ì§€í‘œ & ì‹œê°í™”")
    def group_unsettled(df: pd.DataFrame, title: str):
        base = df[~df["is_settled"]].copy().dropna(subset=["ê¸ˆì•¡_num"])
        if base.empty: st.info(f"{title}: ë¯¸ì •ì‚° ì—†ìŒ"); return
        agg = base.groupby("ì—…ì²´ëª…", dropna=False)["ê¸ˆì•¡_num"].sum().reset_index().sort_values(by="ê¸ˆì•¡_num", ascending=False).head(20)
        st.markdown(f"**{title} - ë¯¸ì •ì‚° ê¸ˆì•¡ ìƒìœ„ 20 ì—…ì²´**")
        chart = alt.Chart(agg.dropna()).mark_bar().encode(x=alt.X("ê¸ˆì•¡_num:Q", title="ê¸ˆì•¡ í•©ê³„"), y=alt.Y("ì—…ì²´ëª…:N", sort="-x", title="ì—…ì²´ëª…")).properties(height=360)
        st.altair_chart(chart, use_container_width=True)
        display_df(agg.rename(columns={"ê¸ˆì•¡_num": "ê¸ˆì•¡í•©ê³„"}), height=260)

    c1, c2 = st.columns(2)
    with c1: group_unsettled(sunsu_s, "ì„ ìˆ˜ê¸ˆ")
    with c2: group_unsettled(seon_s, "ì„ ê¸‰ê¸ˆ")

    def aging_chart(df: pd.DataFrame, title: str):
        col = "ê²½ê³¼ê¸°ê°„(ê°œì›”)" if "ê²½ê³¼ê¸°ê°„(ê°œì›”)" in df.columns else None
        if col is None or df.empty: st.info(f"{title}: 'ê²½ê³¼ê¸°ê°„(ê°œì›”)' ì»¬ëŸ¼ì´ ì—†ì–´ ì—ì´ì§• ì°¨íŠ¸ë¥¼ ìƒëµí•©ë‹ˆë‹¤."); return
        base = df.dropna(subset=["ê¸ˆì•¡_num"]).copy()
        def bucket(x):
            try: v = float(x)
            except Exception: return "ë¯¸ìƒ"
            if v < 1: return "0-1ê°œì›”"
            if v < 3: return "1-3ê°œì›”"
            if v < 6: return "3-6ê°œì›”"
            if v < 12: return "6-12ê°œì›”"
            if v < 24: return "12-24ê°œì›”"
            return "24ê°œì›”+"
        base["ë²„í‚·"] = base[col].apply(bucket)
        agg = base.groupby("ë²„í‚·")["ê¸ˆì•¡_num"].sum().reset_index()
        order = ["0-1ê°œì›”", "1-3ê°œì›”", "3-6ê°œì›”", "6-12ê°œì›”", "12-24ê°œì›”", "24ê°œì›”+"]
        agg["ë²„í‚·"] = pd.Categorical(agg["ë²„í‚·"], categories=order, ordered=True); agg = agg.sort_values("ë²„í‚·")
        chart = alt.Chart(agg).mark_bar().encode(x=alt.X("ë²„í‚·:N", sort=order, title="ê²½ê³¼ê¸°ê°„ ë²„í‚·"), y=alt.Y("ê¸ˆì•¡_num:Q", title="ê¸ˆì•¡ í•©ê³„")).properties(height=300)
        st.markdown(f"**{title} - ì—ì´ì§•(ê°œì›”) ë¶„í¬**")
        st.altair_chart(chart, use_container_width=True)
        display_df(agg.rename(columns={"ê¸ˆì•¡_num": "ê¸ˆì•¡í•©ê³„"}), height=240)

    c3, c4 = st.columns(2)
    with c3: aging_chart(sunsu_s, "ì„ ìˆ˜ê¸ˆ")
    with c4: aging_chart(seon_s, "ì„ ê¸‰ê¸ˆ")

# -----------------------------
# ğŸ§­ ê³ ê¸‰ ê²€ìƒ‰
# -----------------------------
with tab4:
    st.subheader("ê°•í™”ëœ ê²€ìƒ‰(ì„ ìˆ˜ê¸ˆ/ì„ ê¸‰ê¸ˆ í†µí•©)")
    sunsu_view = sunsu_s.copy(); sunsu_view["êµ¬ë¶„"] = "ì„ ìˆ˜ê¸ˆ"
    seon_view = seon_s.copy();   seon_view["êµ¬ë¶„"] = "ì„ ê¸‰ê¸ˆ"
    all_view = pd.concat([sunsu_view, seon_view], ignore_index=True, sort=False)

    col1, col2, col3 = st.columns(3)
    with col1: kw = st.text_input("í‚¤ì›Œë“œ(ì—…ì²´/ê³„ì•½/í…ìŠ¤íŠ¸/ì „í‘œë²ˆí˜¸/ê¸ˆí˜•/ê³ ìœ ë„˜ë²„)", value="")
    with col2: min_amt = st.number_input("ìµœì†Œ ê¸ˆì•¡", value=0, step=1000)
    with col3: max_amt = st.number_input("ìµœëŒ€ ê¸ˆì•¡(0=ì œí•œì—†ìŒ)", value=0, step=1000)

    col4, col5, col6 = st.columns(3)
    with col4: start_date = st.date_input("ì „ê¸°ì¼ From", value=None)
    with col5: end_date = st.date_input("ì „ê¸°ì¼ To", value=None)
    with col6: only_due_this_month = st.checkbox("ë‹¹ì›”ì˜ˆì •ë§Œ", value=False)

    col7, col8 = st.columns(2)
    with col7: status_sel = st.multiselect("ìƒíƒœ(ì„¸ë¶€) ì„ íƒ", options=sorted(all_view["ìƒíƒœ(ì„¸ë¶€)"].dropna().unique().tolist()), default=[])
    with col8: pipeline_sel = st.multiselect("íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì„ íƒ", options=[x for x in ["ì§€ì—°","ë‹¹ì¼","D-3","D-7","ë‹¹ì›”(8ì¼+)"] if x in all_view["íŒŒì´í”„ë¼ì¸"].dropna().unique()], default=[])

    res = all_view.copy()
    res = res[(res["ê¸ˆì•¡_num"].fillna(0) >= (min_amt or 0))]
    if max_amt and max_amt > 0: res = res[(res["ê¸ˆì•¡_num"].fillna(0) <= max_amt)]
    if start_date: res = res[res["ì „ê¸°ì¼_parsed"].fillna(pd.Timestamp("1900-01-01")) >= pd.Timestamp(start_date)]
    if end_date:   res = res[res["ì „ê¸°ì¼_parsed"].fillna(pd.Timestamp("2999-12-31")) <= pd.Timestamp(end_date)]
    if only_due_this_month:
        now = pd.Timestamp.now()
        due = res["íšŒìˆ˜ëª©í‘œì¼ì"] if "íšŒìˆ˜ëª©í‘œì¼ì" in res.columns else pd.Series(pd.NaT, index=res.index)
        res = res[(~res["is_settled"]) & (due.notna()) & (due.dt.to_period("M") == now.to_period("M"))]
    if status_sel:   res = res[res["ìƒíƒœ(ì„¸ë¶€)"].isin(status_sel)]
    if pipeline_sel: res = res[res["íŒŒì´í”„ë¼ì¸"].isin(pipeline_sel)]

    if kw.strip():
        k = kw.strip().upper()
        def contains_any(s):
            if s is None or (isinstance(s, float) and math.isnan(s)): return False
            return k in str(s).upper()
        search_cols = [c for c in ["ì—…ì²´ëª…","ê³„ì•½ë²ˆí˜¸","í…ìŠ¤íŠ¸","ì „í‘œë²ˆí˜¸","ê¸ˆí˜•ë§ˆìŠ¤í„°","ê¸ˆí˜•ë§ˆìŠ¤í„°ë‚´ì—­","ê³ ìœ ë„˜ë²„"] if c in res.columns]
        mask = False
        for c in search_cols: mask = mask | res[c].apply(contains_any)
        res = res[mask]

    sort_cols = [c for c in ["êµ¬ë¶„","is_settled","íšŒìˆ˜ëª©í‘œì¼ì","ì „ê¸°ì¼_parsed","ê¸ˆì•¡_num"] if c in res.columns]
    if sort_cols: res = res.sort_values(by=sort_cols, ascending=[True, True, True, True, False]).reset_index(drop=True)
    show_cols = [c for c in ["êµ¬ë¶„","ì˜ì—…ë‹´ë‹¹_í‘œì¤€","ì—…ì²´ëª…","ê³„ì•½ë²ˆí˜¸","ê³ ìœ ë„˜ë²„","ì „ê¸°ì¼_parsed","íšŒìˆ˜ëª©í‘œì¼ì","íŒŒì´í”„ë¼ì¸","ìƒíƒœ(ì„¸ë¶€)","ê¸ˆì•¡_num","ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸","ì •ì‚°ì—¬ë¶€","ì •ì‚°ì§„í–‰í˜„í™©","ì§„í–‰í˜„í™©","ì—°ë½ì´ë ¥","í…ìŠ¤íŠ¸","ë¹„ê³ "] if c in res.columns]
    display_df(res[show_cols], height=520)
    st.download_button("ê²€ìƒ‰ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", res[show_cols].to_csv(index=False).encode("utf-8-sig"), file_name="search_results.csv", mime="text/csv")

# -----------------------------
# ğŸ—‚ 3ë‹¨ ê·¸ë¦¬ë“œ
# -----------------------------
with tab5:
    st.subheader("ë‹´ë‹¹ì â†’ ê³ ê° â†’ ê³„ì•½ 3ë‹¨ ê·¸ë¦¬ë“œ")
    all3 = pd.concat([sunsu_s.assign(êµ¬ë¶„="ì„ ìˆ˜ê¸ˆ"), seon_s.assign(êµ¬ë¶„="ì„ ê¸‰ê¸ˆ")], ignore_index=True, sort=False)
    if all3.empty:
        st.info("ë°ì´í„° ì—†ìŒ")
    else:
        owners = sorted(all3["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"].dropna().unique().tolist())
        for owner in owners:
            with st.expander(f"ë‹´ë‹¹ì: {owner}"):
                sub = all3[all3["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"] == owner].copy()
                customers = sorted(sub["ì—…ì²´ëª…"].dropna().unique().tolist())
                for cust in customers:
                    st.markdown(f"**ê³ ê°: {cust}**")
                    sub2 = sub[sub["ì—…ì²´ëª…"] == cust].copy()
                    cols = [c for c in ["ê³„ì•½ë²ˆí˜¸","êµ¬ë¶„","ì „ê¸°ì¼_parsed","íšŒìˆ˜ëª©í‘œì¼ì","íŒŒì´í”„ë¼ì¸","ìƒíƒœ(ì„¸ë¶€)","ê¸ˆì•¡_num","ì§„í–‰í˜„í™©","ì •ì‚°ì§„í–‰í˜„í™©","ì—°ë½ì´ë ¥","í…ìŠ¤íŠ¸","ë¹„ê³ "] if c in sub2.columns]
                    display_df(sub2[cols], height=240)

# -----------------------------
# ğŸ—“ ì£¼ê°„ ê³„íší‘œ
# -----------------------------
with tab6:
    st.subheader("ì£¼ê°„ íšŒìˆ˜ ê³„íší‘œ (ë¯¸ì •ì‚° + ì´ë²ˆì£¼ ê¸°í•œ/ì§€ì—° í¬í•¨)")
    now = pd.Timestamp.now().normalize()
    week_start = now - pd.Timedelta(days=now.weekday())
    week_end = week_start + pd.Timedelta(days=6)

    def weekly_plan(df: pd.DataFrame) -> pd.DataFrame:
        if df.empty: return df
        if "íšŒìˆ˜ëª©í‘œì¼ì" not in df.columns:
            return df.iloc[0:0].copy()
        due = df["íšŒìˆ˜ëª©í‘œì¼ì"]
        cond = (~df["is_settled"]) & (due.notna()) & ((due < week_start) | ((due >= week_start) & (due <= week_end)))
        out = df[cond].copy()
        weekday = out["íšŒìˆ˜ëª©í‘œì¼ì"].dt.weekday
        names = {0:"ì›”",1:"í™”",2:"ìˆ˜",3:"ëª©",4:"ê¸ˆ",5:"í† ",6:"ì¼"}
        out["ìš”ì¼"] = weekday.map(names)
        return out

    week_all = pd.concat([weekly_plan(sunsu_s.assign(êµ¬ë¶„="ì„ ìˆ˜ê¸ˆ")), weekly_plan(seon_s.assign(êµ¬ë¶„="ì„ ê¸‰ê¸ˆ"))], ignore_index=True, sort=False)
    if week_all.empty:
        st.info("ì´ë²ˆ ì£¼ ê³„íš ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        show_cols = [c for c in ["ìš”ì¼","êµ¬ë¶„","ì˜ì—…ë‹´ë‹¹_í‘œì¤€","ì—…ì²´ëª…","ê³„ì•½ë²ˆí˜¸","ê³ ìœ ë„˜ë²„","íšŒìˆ˜ëª©í‘œì¼ì","íŒŒì´í”„ë¼ì¸","ìƒíƒœ(ì„¸ë¶€)","ê¸ˆì•¡_num","ì—°ë½ì´ë ¥","í…ìŠ¤íŠ¸","ë¹„ê³ "] if c in week_all.columns]
        week_all = week_all.sort_values(by=["ìš”ì¼","ì˜ì—…ë‹´ë‹¹_í‘œì¤€","ì—…ì²´ëª…","ê³„ì•½ë²ˆí˜¸"])
        display_df(week_all[show_cols], height=520)
        st.download_button("ì£¼ê°„ ê³„íší‘œ CSV ë‹¤ìš´ë¡œë“œ", week_all[show_cols].to_csv(index=False).encode("utf-8-sig"), file_name="weekly_collection_plan.csv", mime="text/csv")

# -----------------------------
# ğŸ“œ íˆìŠ¤í† ë¦¬
# -----------------------------
with tab7:
    st.subheader("ğŸ“œ ë³€ê²½ íˆìŠ¤í† ë¦¬")
    curr = build_current_snapshot()
    prev = load_last_snapshot()
    diffs = diff_snapshots(prev, curr)
    if diffs.empty: st.info("ì§ì „ ìŠ¤ëƒ…ìƒ· ëŒ€ë¹„ ë³€ê²½ ì—†ìŒ");
    else: display_df(diffs[["ë³€ê²½ì‹œê°","êµ¬ë¶„","ì˜ì—…ë‹´ë‹¹_í‘œì¤€","ì—…ì²´ëª…","ê³„ì•½ë²ˆí˜¸","í‚¤","ë³€ê²½í•­ëª©","ì´ì „ê°’","í˜„ì¬ê°’"]], height=360)
    if st.button("í˜„ì¬ ìƒíƒœ ìŠ¤ëƒ…ìƒ· ì €ì¥"):
        save_snapshot(curr)
        st.success("ìŠ¤ëƒ…ìƒ·ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ë¶€í„° ë³€ê²½ë‚´ì—­ì´ ë¹„êµë©ë‹ˆë‹¤.")

# -----------------------------
# ğŸ“£ ì•Œë¦¼ ë¦¬í¬íŠ¸
# -----------------------------
st.markdown("---")
st.subheader("ğŸ“£ ì•Œë¦¼ ë¦¬í¬íŠ¸: ì˜ì—…ë‹´ë‹¹ë³„ ë‹¹ì›”ì˜ˆì •/ì—°ì²´ ëª©ë¡")

def build_alert_df(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty: return df
    for needed in ["is_settled", "ìƒíƒœ"]:
        if needed not in df.columns: return df.iloc[0:0].copy()
    base = df[(~df["is_settled"]) & (df["ìƒíƒœ"].isin(["ì—°ì²´","ë‹¹ì›”ì˜ˆì •"]))].copy()
    desired = ["ì˜ì—…ë‹´ë‹¹_í‘œì¤€","ì—…ì²´ëª…","ê³„ì•½ë²ˆí˜¸","ê³ ìœ ë„˜ë²„","ìƒíƒœ","íŒŒì´í”„ë¼ì¸","íšŒìˆ˜ëª©í‘œì¼ì","ê¸ˆì•¡_num","ì§„í–‰í˜„í™©","ì •ì‚°ì§„í–‰í˜„í™©","ì—°ë½ì´ë ¥","í…ìŠ¤íŠ¸","ë¹„ê³ ","êµ¬ë¶„"]
    cols = [c for c in desired if c in base.columns]
    base = base[cols]
    return base

alert_all = pd.concat([build_alert_df(sunsu_s.assign(êµ¬ë¶„="ì„ ìˆ˜ê¸ˆ")), build_alert_df(seon_s.assign(êµ¬ë¶„="ì„ ê¸‰ê¸ˆ"))], ignore_index=True, sort=False)
if alert_all.empty:
    st.info("ì•Œë¦¼ ëŒ€ìƒ(ë‹¹ì›”ì˜ˆì •/ì—°ì²´)ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    owners = sorted(alert_all["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"].dropna().unique().tolist()) if "ì˜ì—…ë‹´ë‹¹_í‘œì¤€" in alert_all.columns else []
    mem = io.BytesIO()
    with zipfile.ZipFile(mem, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
        for o in owners:
            sub = alert_all[alert_all["ì˜ì—…ë‹´ë‹¹_í‘œì¤€"] == o].copy()
            if sub.empty: continue
            csv_bytes = sub.to_csv(index=False).encode("utf-8-sig")
            zf.writestr(f"{o}_ì•Œë¦¼ëŒ€ìƒ.csv", csv_bytes)
    mem.seek(0)
    st.download_button("ë‹´ë‹¹ìë³„ ì•Œë¦¼ CSV(zip) ë‹¤ìš´ë¡œë“œ", data=mem, file_name="alerts_by_owner.zip", mime="application/zip")

st.caption("ì™„ë£Œ íŒì •ì€ ì •ì‚°ì—¬ë¶€ O/Y/1 ë˜ëŠ” ì •ì‚°/ì§„í–‰ í˜„í™©ì˜ ëª…í™•í•œ 'ì™„ë£Œ' ì‹ í˜¸ê°€ ìˆê³  ë¶€ì • í‚¤ì›Œë“œ(ë¯¸ì™„ë£Œ/ì˜ˆì •/ì§„í–‰ì¤‘ ë“±)ê°€ ì—†ì„ ë•Œë§Œ Trueì…ë‹ˆë‹¤. í‘œì˜ ê¸ˆì•¡ì€ í™”ë©´ì—ì„œë§Œ ì½¤ë§ˆ ë¬¸ìì—´ë¡œ í‘œì‹œë˜ë©°, ë‚´ë¶€ ê³„ì‚°/CSVëŠ” ìˆ«ìë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
