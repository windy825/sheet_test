
# -*- coding: utf-8 -*-
"""
ë¡œì»¬ìš© ì„ ìˆ˜/ì„ ê¸‰ê¸ˆ ë§¤ì¹­ & ëŒ€ì‹œë³´ë“œ (Streamlit)
------------------------------------------------
ìš”êµ¬ì‚¬í•­ ìš”ì•½
- íŠ¹ì • "ì„ ìˆ˜ê¸ˆ"ê³¼ ë§¤ì¹­ë  ìˆ˜ ìˆëŠ” "ì„ ê¸‰ê¸ˆ"ë“¤ì„ ì‰½ê²Œ ì¡°íšŒ
- ìë™ ë§¤ì¹­ ì œì•ˆ(1:N ì¡°í•© íƒìƒ‰ í¬í•¨)
- ì‹¬í™” ëŒ€ì‹œë³´ë“œ

ì‹¤í–‰ ë°©ë²•
1) Python 3.9+ ê¶Œì¥
2) ì•„ë˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
   pip install streamlit pandas numpy openpyxl altair
3) ì‹¤í–‰
   streamlit run app.py

ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ(ì˜µì…˜):
- ë³¸ ì•±ì€ ê¸°ë³¸ì ìœ¼ë¡œ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ” Excel íŒŒì¼ì„ ì°¾ê±°ë‚˜, ì‚¬ì´ë“œë°”ì—ì„œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì˜ˆì‹œ: /mnt/data/2025.07ì›”ë§ ì„ ìˆ˜ì„ ê¸‰ê¸ˆ í˜„í™©_20250811.xlsx
"""
from __future__ import annotations

import itertools
import math
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st
from difflib import SequenceMatcher

# -----------------------------
# ì„¤ì •
# -----------------------------
st.set_page_config(
    page_title="ì„ ìˆ˜Â·ì„ ê¸‰ê¸ˆ ë§¤ì¹­ & ëŒ€ì‹œë³´ë“œ",
    layout="wide",
    page_icon="ğŸ“Š",
)

DEFAULT_EXCEL_PATH = "./2025.07ì›”ë§ ì„ ìˆ˜ì„ ê¸‰ê¸ˆ í˜„í™©_20250811.xlsx"  # ë¡œì»¬ì—ì„œ ë™ì¼ í´ë”ì— ë‘˜ ê²½ìš° ìë™ ë¡œë“œ ì‹œë„

# -----------------------------
# ìœ í‹¸
# -----------------------------
def norm_col(c: str) -> str:
    if not isinstance(c, str):
        return c
    return (
        c.replace("\\n", "")
         .replace("\n", "")
         .replace("\r", "")
         .replace(" ", "")
         .strip()
    )

def normalize_text(s: Optional[str]) -> str:
    if s is None or (isinstance(s, float) and math.isnan(s)):
        return ""
    s = str(s)
    return "".join(ch for ch in s.upper().strip())

def text_sim(a: str, b: str) -> float:
    a, b = normalize_text(a), normalize_text(b)
    if not a or not b:
        return 0.0
    return SequenceMatcher(None, a, b).ratio()

def to_number(x) -> Optional[float]:
    try:
        if pd.isna(x):
            return None
        # ë¬¸ìì—´ ê¸ˆì•¡ì— ì½¤ë§ˆ ì²˜ë¦¬
        if isinstance(x, str):
            x = x.replace(",", "").replace(" ", "")
        v = float(x)
        if math.isfinite(v):
            return v
        return None
    except Exception:
        return None

def to_date(x) -> Optional[pd.Timestamp]:
    try:
        if pd.isna(x):
            return None
        return pd.to_datetime(x)
    except Exception:
        return None

def choose_amount_row(row: pd.Series) -> Optional[float]:
    # ê¸ˆì•¡ ìš°ì„ ìˆœìœ„: ì „í‘œí†µí™”ì•¡ -> í˜„ì§€í†µí™”ì•¡
    for key in ["ì „í‘œí†µí™”ì•¡", "í˜„ì§€í†µí™”ì•¡"]:
        if key in row.index:
            v = to_number(row[key])
            if v is not None:
                return v
    # ë°±ì—…: ê¸ˆì•¡ í˜¹ì€ Debit/Credit ê³„ì—´ì´ ìˆìœ¼ë©´ í™•ì¥ ê°€ëŠ¥
    return None

def days_between(d1: Optional[pd.Timestamp], d2: Optional[pd.Timestamp]) -> Optional[int]:
    if d1 is None or d2 is None:
        return None
    return abs((pd.to_datetime(d1) - pd.to_datetime(d2)).days)

# -----------------------------
# ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬
# -----------------------------
@st.cache_data(show_spinner=False)
def load_excel(excel_bytes_or_path) -> Dict[str, pd.DataFrame]:
    if excel_bytes_or_path is None:
        return {}
    try:
        xls = pd.ExcelFile(excel_bytes_or_path)
        sheets = {}
        for s in xls.sheet_names:
            df = pd.read_excel(xls, sheet_name=s)
            # ì»¬ëŸ¼ ì •ê·œí™”
            df.columns = [norm_col(c) for c in df.columns]
            # ë¹ˆ í–‰ ì œê±°(ì „ë¶€ NaN)
            df = df.dropna(how="all")
            sheets[s] = df
        return sheets
    except Exception as e:
        st.error(f"ì—‘ì…€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def find_sheet_case_insensitive(sheets: Dict[str, pd.DataFrame], target: str) -> Optional[str]:
    target_norm = normalize_text(target)
    for name in sheets.keys():
        if normalize_text(name) == target_norm:
            return name
    # ë„“ê²Œ í¬í•¨ ê²€ìƒ‰
    for name in sheets.keys():
        if target_norm in normalize_text(name):
            return name
    return None

# -----------------------------
# ë§¤ì¹­ ìŠ¤ì½”ì–´
# -----------------------------
def calc_match_score(sunsu: pd.Series, seongeup: pd.Series, today: datetime, date_half_life_days: int = 90) -> Tuple[float, Dict[str, float]]:
    """
    ë‘ í–‰(ì„ ìˆ˜ê¸ˆ 1ê°œ vs ì„ ê¸‰ê¸ˆ 1ê°œ)ì— ëŒ€í•œ ë§¤ì¹­ ì ìˆ˜(0~100)ì™€ êµ¬ì„±ìš”ì†Œ ì„¸ë¶€ ì ìˆ˜ ë°˜í™˜
    ê°€ì¤‘ì¹˜ ì„¤ê³„(ê²½í—˜ì¹˜ ê¸°ë°˜, í•„ìš”ì‹œ ì‚¬ì´ë“œë°”ì—ì„œ ì¡°ì • ê°€ëŠ¥í•˜ë„ë¡ ë³€ê²½ ê°€ëŠ¥)
    """
    weights = {
        "linked_id": 60.0,   # ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸ = ì„ ìˆ˜ê¸ˆ ê³ ìœ ë„˜ë²„
        "contract": 20.0,    # ê³„ì•½ë²ˆí˜¸ ì™„ì „ì¼ì¹˜
        "name": 10.0,        # ì—…ì²´ëª… ìœ ì‚¬ë„(0~1)*10
        "date": 5.0,         # ì¼ì ê·¼ì ‘ë„
        "text": 5.0,         # í…ìŠ¤íŠ¸ì— ê³„ì•½ë²ˆí˜¸ í¬í•¨
        "amount": 10.0,      # ê¸ˆì•¡ ê·¼ì ‘ë„
    }

    # ê³µí†µ ì»¬ëŸ¼ ì•ˆì „ ì ‘ê·¼
    def get(row: pd.Series, key: str) -> Optional[str]:
        return row.get(key) if key in row.index else None

    # Linked ID
    linked = 0.0
    seon_link = get(seongeup, "ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸") or get(seongeup, "ì •ì‚°\nì„ ìˆ˜ê¸ˆ\nê³ ìœ ë²ˆí˜¸")
    sun_id = get(sunsu, "ê³ ìœ ë„˜ë²„")
    if seon_link and sun_id and str(seon_link).strip() == str(sun_id).strip():
        linked = 1.0

    # ê³„ì•½ë²ˆí˜¸
    contract_equal = 0.0
    if get(sunsu, "ê³„ì•½ë²ˆí˜¸") and get(seongeup, "ê³„ì•½ë²ˆí˜¸"):
        if str(get(sunsu, "ê³„ì•½ë²ˆí˜¸")).strip() == str(get(seongeup, "ê³„ì•½ë²ˆí˜¸")).strip():
            contract_equal = 1.0

    # ì—…ì²´ëª… ìœ ì‚¬ë„
    name_sim = text_sim(get(sunsu, "ì—…ì²´ëª…"), get(seongeup, "ì—…ì²´ëª…"))

    # ì¼ì ê·¼ì ‘(ì§€ìˆ˜ê°ì‡ )
    d1 = to_date(get(sunsu, "ì „ê¸°ì¼"))
    d2 = to_date(get(seongeup, "ì „ê¸°ì¼"))
    date_score = 0.0
    if d1 is not None and d2 is not None:
        dd = abs((d1 - d2).days)
        # ì ˆë°˜ê°ì‡ ì¼(date_half_life_days) ê¸°ì¤€ì˜ ì§€ìˆ˜ ì ìˆ˜
        # dd=0 ->1, dd=half_life ->0.5, dd=2*half_life->0.25 ...
        if date_half_life_days <= 0:
            date_score = 1.0 if dd == 0 else 0.0
        else:
            date_score = 0.5 ** (dd / float(date_half_life_days))

    # í…ìŠ¤íŠ¸ì— ê³„ì•½ë²ˆí˜¸ í¬í•¨
    text_contains = 0.0
    if get(seongeup, "í…ìŠ¤íŠ¸") and get(sunsu, "ê³„ì•½ë²ˆí˜¸"):
        if str(get(sunsu, "ê³„ì•½ë²ˆí˜¸")).strip() in str(get(seongeup, "í…ìŠ¤íŠ¸")):
            text_contains = 1.0

    # ê¸ˆì•¡ ê·¼ì ‘
    amt_sun = choose_amount_row(sunsu)
    amt_seon = choose_amount_row(seongeup)
    amount_score = 0.0
    if amt_sun is not None and amt_seon is not None and amt_sun != 0:
        diff = abs(amt_sun - amt_seon)
        rel = max(0.0, 1.0 - (diff / abs(amt_sun)))  # 0~1
        amount_score = rel

    parts = {
        "linked_id": linked * weights["linked_id"],
        "contract": contract_equal * weights["contract"],
        "name": name_sim * weights["name"],
        "date": date_score * weights["date"],
        "text": text_contains * weights["text"],
        "amount": amount_score * weights["amount"],
    }
    total = sum(parts.values())
    return total, parts

# -----------------------------
# 1:N ì¡°í•© íƒìƒ‰(ê°€ë²¼ìš´ íœ´ë¦¬ìŠ¤í‹±)
# -----------------------------
def propose_combinations(target_amount: float,
                         candidates: pd.DataFrame,
                         amount_col: str = "ê¸ˆì•¡",
                         max_depth: int = 6,
                         max_nodes: int = 800,
                         tolerance: float = 0.05) -> List[Dict]:
    """
    Greedy + ì œí•œì  ë°±íŠ¸ë˜í‚¹ìœ¼ë¡œ 1:N ì¡°í•© ì œì•ˆ
    - candidatesì—ëŠ” ê¸ˆì•¡ ì—´ì´ ì¡´ì¬í•´ì•¼ í•¨(ë¯¸ë¦¬ ì¶”ì¶œí•´ì„œ ë„£ìŒ)
    - tolerance: ëª©í‘œ ëŒ€ë¹„ í—ˆìš© ì˜¤ì°¨(ë¹„ìœ¨)
    """
    rows = candidates.copy()
    rows = rows[rows[amount_col].notna()].reset_index(drop=True)
    rows = rows.sort_values(by=amount_col, key=lambda s: (target_amount - s).abs())

    best_solutions: List[Dict] = []
    visited = 0

    def backtrack(start_idx: int, chosen_idx: List[int], sum_amt: float):
        nonlocal visited, best_solutions
        if visited >= max_nodes or len(chosen_idx) > max_depth:
            return
        visited += 1

        gap = target_amount - sum_amt
        # ìˆ˜ìš© ë²”ìœ„ ë‚´ë©´ ì†”ë£¨ì…˜ ì¶”ê°€
        if abs(gap) <= abs(target_amount) * tolerance:
            combo = rows.loc[chosen_idx]
            best_solutions.append({
                "indices": chosen_idx.copy(),
                "rows": combo.copy(),
                "sum": float(sum_amt),
                "gap": float(gap),
                "count": len(chosen_idx),
            })
            # ë” ê¹Šê²Œ ê°€ì§€ ì•Šê³  ì¢…ë£Œ(ì¶”ê°€ í™•ì¥ ë°©ì§€)
            return

        # ê°€ì§€ì¹˜ê¸°: ì´ˆê³¼ë˜ì—ˆê³  target > 0ì¸ ê²½ìš°
        if (target_amount >= 0 and sum_amt > target_amount * (1 + tolerance)) or \
           (target_amount < 0 and sum_amt < target_amount * (1 + tolerance)):
            return

        # íƒìƒ‰ í™•ì¥
        for i in range(start_idx, len(rows)):
            amt = rows.iloc[i][amount_col]
            if pd.isna(amt):
                continue
            backtrack(i + 1, chosen_idx + [i], sum_amt + amt)

    backtrack(0, [], 0.0)
    # ìƒìœ„ ì†”ë£¨ì…˜ ì •ë ¬: ì˜¤ì°¨ -> í•­ëª©ìˆ˜ -> ê¸ˆì•¡í•© ê·¼ì ‘
    best_solutions = sorted(best_solutions, key=lambda x: (abs(x["gap"]), x["count"]))
    # ì¤‘ë³µ ì œê±°(ê°™ì€ ì¸ë±ìŠ¤ ì¡°í•©)
    unique = []
    seen = set()
    for sol in best_solutions:
        key = tuple(sol["indices"])
        if key not in seen:
            seen.add(key)
            unique.append(sol)
    return unique[:10]

# -----------------------------
# ì‚¬ì´ë“œë°” - ë°ì´í„° ë¡œë”©
# -----------------------------
st.sidebar.header("ë°ì´í„°")
excel_file = st.sidebar.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"], accept_multiple_files=False)

default_used = False
sheets = {}
if excel_file is not None:
    sheets = load_excel(excel_file)
else:
    # ë¡œì»¬ ê¸°ë³¸ ê²½ë¡œ ìë™ ë¡œë“œ ì‹œë„
    try:
        with open(DEFAULT_EXCEL_PATH, "rb") as f:
            sheets = load_excel(f)
            default_used = True
            st.sidebar.info("ê¸°ë³¸ ê²½ë¡œì—ì„œ ì—‘ì…€ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    except Exception:
        st.sidebar.warning("ì—‘ì…€ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")

if not sheets:
    st.stop()

s_sunsu = find_sheet_case_insensitive(sheets, "ì„ ìˆ˜ê¸ˆ")
s_seongeup = find_sheet_case_insensitive(sheets, "ì„ ê¸‰ê¸ˆ")

if s_sunsu is None or s_seongeup is None:
    st.error("ì‹œíŠ¸ ì´ë¦„ 'ì„ ìˆ˜ê¸ˆ', 'ì„ ê¸‰ê¸ˆ'ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‹œíŠ¸ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

df_sunsu = sheets[s_sunsu].copy()
df_seon = sheets[s_seongeup].copy()

# ì¤‘ìš” í‚¤ ì»¬ëŸ¼ ê°€ì‹œí™”ìš© ë³„ì¹­/ì¡´ì¬ ì²´í¬
for df in (df_sunsu, df_seon):
    for old, new in [
        ("ì •ì‚°\nì„ ìˆ˜ê¸ˆ\nê³ ìœ ë²ˆí˜¸", "ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸"),
        ("ì •ì‚°ì—¬ë¶€\n(O/X)", "ì •ì‚°ì—¬ë¶€"),
        ("ê³ ê°ëª…\n(ë“œë¡­ë‹¤ìš´)", "ê³ ê°ëª…"),
        ("ì •ì‚°\nì„ ìˆ˜ê¸ˆ\nê³ ìœ ë²ˆí˜¸", "ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸"),
        ("íšŒìˆ˜ëª©í‘œì¼ì •\n(YY/MM)", "íšŒìˆ˜ëª©í‘œì¼ì •(YY/MM)"),
        ("ê²½ê³¼ê¸°ê°„\n(ê°œì›”)", "ê²½ê³¼ê¸°ê°„(ê°œì›”)"),
    ]:
        if old in df.columns and new not in df.columns:
            df.rename(columns={old: new}, inplace=True)

# ê¸ˆì•¡ ì»¬ëŸ¼ ìƒì„±(ì „í‘œí†µí™”ì•¡/í˜„ì§€í†µí™”ì•¡ ì¤‘ í•˜ë‚˜ë¥¼ 'ê¸ˆì•¡'ìœ¼ë¡œ)
def unify_amount_col(df: pd.DataFrame) -> pd.DataFrame:
    if "ê¸ˆì•¡" not in df.columns:
        df["ê¸ˆì•¡"] = df.apply(choose_amount_row, axis=1)
    return df

df_sunsu = unify_amount_col(df_sunsu)
df_seon = unify_amount_col(df_seon)

# ë‚ ì§œ íŒŒì‹± ì»¬ëŸ¼
for df in (df_sunsu, df_seon):
    if "ì „ê¸°ì¼" in df.columns:
        df["ì „ê¸°ì¼_parsed"] = pd.to_datetime(df["ì „ê¸°ì¼"], errors="coerce")

# -----------------------------
# ì‚¬ì´ë“œë°” - ë§¤ì¹­ ì˜µì…˜
# -----------------------------
st.sidebar.header("ë§¤ì¹­ ì˜µì…˜")
date_half_life_days = st.sidebar.slider("ì¼ì ê·¼ì ‘ë„ ì ˆë°˜ê°ì‡ ì¼(ì¼)", min_value=15, max_value=180, value=90, step=15)
score_threshold = st.sidebar.slider("í›„ë³´ í‘œì‹œ ìµœì†Œì ìˆ˜", min_value=0, max_value=100, value=40, step=5)
combo_tolerance = st.sidebar.slider("ì¡°í•© í•©ê³„ í—ˆìš©ì˜¤ì°¨(Â±%)", min_value=1, max_value=20, value=5, step=1) / 100.0
combo_max_depth = st.sidebar.slider("ì¡°í•© ìµœëŒ€ í•­ëª© ìˆ˜", min_value=2, max_value=10, value=6, step=1)

st.sidebar.caption("â€» ì ìˆ˜ëŠ” ë§í¬ë“œID>ê³„ì•½ë²ˆí˜¸>ê¸ˆì•¡/ì—…ì²´ëª…/ì¼ì/í…ìŠ¤íŠ¸ ìˆœìœ¼ë¡œ ê°€ì¤‘ì¹˜ê°€ ì ìš©ë©ë‹ˆë‹¤.")

# -----------------------------
# íƒ­ êµ¬ì„±
# -----------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ” ë§¤ì¹­ ì¡°íšŒ", "âš™ï¸ ì¼ê´„ ë§¤ì¹­ ì œì•ˆ", "ğŸ“Š ëŒ€ì‹œë³´ë“œ"])

# -----------------------------
# ğŸ” ë§¤ì¹­ ì¡°íšŒ
# -----------------------------
with tab1:
    st.subheader("íŠ¹ì • ì„ ìˆ˜ê¸ˆê³¼ ë§¤ì¹­ë˜ëŠ” ì„ ê¸‰ê¸ˆ í›„ë³´ ì¡°íšŒ")
    # ì„ ìˆ˜ê¸ˆ ì„ íƒ ì…€ë ‰íŠ¸ë°•ìŠ¤
    def sunsu_label(row: pd.Series) -> str:
        gid = str(row.get("ê³ ìœ ë„˜ë²„", ""))
        comp = str(row.get("ì—…ì²´ëª…", ""))
        contract = str(row.get("ê³„ì•½ë²ˆí˜¸", ""))
        date = row.get("ì „ê¸°ì¼_parsed", row.get("ì „ê¸°ì¼", ""))
        amt = row.get("ê¸ˆì•¡", None)
        amt_str = f"{amt:,.0f}" if isinstance(amt, (int, float, np.number)) and not pd.isna(amt) else "-"
        dstr = ""
        if isinstance(date, pd.Timestamp):
            dstr = date.strftime("%Y-%m-%d")
        else:
            dstr = str(date) if date is not None else ""
        return f"[{gid}] {comp} | ê³„ì•½:{contract} | ì¼ì:{dstr} | ê¸ˆì•¡:{amt_str}"

    sunsu_options = df_sunsu.index.tolist()
    selectable = [(i, sunsu_label(df_sunsu.loc[i])) for i in sunsu_options]
    selected_idx = st.selectbox("ì„ ìˆ˜ê¸ˆ ì„ íƒ", options=[i for i, _ in selectable], format_func=lambda i: dict(selectable)[i])

    if selected_idx is not None:
        target_row = df_sunsu.loc[selected_idx]

        # ê°œë³„ ì„ ê¸‰ê¸ˆê³¼ì˜ ì ìˆ˜ ê³„ì‚°
        today = datetime.now()
        scores = []
        for i, row in df_seon.iterrows():
            total, parts = calc_match_score(target_row, row, today=today, date_half_life_days=date_half_life_days)
            if total >= score_threshold:
                scores.append({
                    "ì„ ê¸‰_index": i,
                    "ì´ì ": round(total, 2),
                    **{f"ì ìˆ˜:{k}": round(v, 2) for k, v in parts.items()},
                    "ê³„ì•½ë²ˆí˜¸": row.get("ê³„ì•½ë²ˆí˜¸"),
                    "ì—…ì²´ëª…": row.get("ì—…ì²´ëª…"),
                    "ì „ê¸°ì¼": row.get("ì „ê¸°ì¼_parsed", row.get("ì „ê¸°ì¼")),
                    "ê¸ˆì•¡": row.get("ê¸ˆì•¡"),
                    "ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸": row.get("ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸"),
                    "í…ìŠ¤íŠ¸": row.get("í…ìŠ¤íŠ¸"),
                    "ê³ ìœ ë„˜ë²„": row.get("ê³ ìœ ë„˜ë²„"),
                })

        cand_df = pd.DataFrame(scores).sort_values(by=["ì´ì "], ascending=False).reset_index(drop=True)
        st.markdown("**ë‹¨ì¼ í•­ëª© í›„ë³´(ì ìˆ˜ ìˆœ)**")
        st.dataframe(cand_df, use_container_width=True, height=400)

        # 1:N ì¡°í•© ì œì•ˆ
        target_amt = target_row.get("ê¸ˆì•¡", None)
        if isinstance(target_amt, (int, float, np.number)) and not pd.isna(target_amt):
            # ê¸ˆì•¡ í•„í„°ë§ ê°•ë„ ì¡°ì ˆì„ ìœ„í•œ í›„ë³´ ì¶•ì†Œ (ê³„ì•½ë²ˆí˜¸/ì—…ì²´ëª… ê·¼ì ‘ ìš°ì„ )
            seed = df_seon.copy()
            def contract_match(r): 
                return str(r.get("ê³„ì•½ë²ˆí˜¸","")).strip() == str(target_row.get("ê³„ì•½ë²ˆí˜¸","")).strip() if r.get("ê³„ì•½ë²ˆí˜¸") is not None else False
            seed["name_sim"] = seed["ì—…ì²´ëª…"].apply(lambda x: text_sim(x, target_row.get("ì—…ì²´ëª…")) if "ì—…ì²´ëª…" in seed.columns else 0.0)
            # 1ì°¨ í•„í„°: ê³„ì•½ë²ˆí˜¸ ì¼ì¹˜ í˜¹ì€ ì—…ì²´ëª… ìœ ì‚¬ë„ >= 0.75
            seed = seed[(seed.apply(contract_match, axis=1)) | (seed["name_sim"] >= 0.75)].copy()
            seed["ê¸ˆì•¡"] = seed["ê¸ˆì•¡"].apply(to_number)
            # ê¸ˆì•¡ì´ 0ì´ê±°ë‚˜ NaN ì œê±°
            seed = seed[seed["ê¸ˆì•¡"].notna() & (seed["ê¸ˆì•¡"] != 0)]
            # ì ˆëŒ€ê°’ì´ target ëŒ€ë¹„ ë„ˆë¬´ í° í•­ëª© ì œì™¸
            seed = seed[seed["ê¸ˆì•¡"].abs() <= abs(target_amt) * (1 + combo_tolerance)].copy()
            # ìµœëŒ€ 80ê°œë¡œ ì œí•œ(ì„±ëŠ¥ ë³´í˜¸)
            seed = seed.sort_values(by="ê¸ˆì•¡", key=lambda s: (abs(target_amt - s))).head(80).reset_index(drop=True)

            if seed.empty:
                st.info("ì¡°í•© íƒìƒ‰ì„ ìœ„í•œ í›„ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ì¡°í•© ì œì•ˆì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                combos = propose_combinations(
                    target_amount=target_amt,
                    candidates=seed,
                    amount_col="ê¸ˆì•¡",
                    max_depth=combo_max_depth,
                    max_nodes=800,
                    tolerance=combo_tolerance,
                )
                st.markdown("**1:N ì¡°í•© í›„ë³´(ì˜¤ì°¨Â·í•­ëª© ìˆ˜ ê¸°ì¤€ ìƒìœ„)**")
                if not combos:
                    st.info("ì¡°ê±´ì— ë§ëŠ” ì¡°í•©ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í—ˆìš©ì˜¤ì°¨(Â±%) ë˜ëŠ” í›„ë³´ í•„í„°ë¥¼ ì™„í™”í•´ë³´ì„¸ìš”.")
                else:
                    # ìƒìœ„ 5ê°œë§Œ í‘œë¡œ ë³€í™˜
                    combo_tables = []
                    for rank, c in enumerate(combos[:5], start=1):
                        tbl = c["rows"].copy()
                        tbl = tbl.assign(_ì¡°í•©ìˆœìœ„=rank)
                        combo_tables.append(tbl.assign(_í•©ê³„=c["sum"], _ê°­=c["gap"]))
                    combo_df = pd.concat(combo_tables, ignore_index=True)
                    # ë³´ê¸° í¸í•˜ê²Œ ì„ íƒ ì»¬ëŸ¼ë§Œ ë…¸ì¶œ
                    show_cols = [col for col in ["_ì¡°í•©ìˆœìœ„", "ê³ ìœ ë„˜ë²„", "ê³„ì•½ë²ˆí˜¸", "ì—…ì²´ëª…", "ì „ê¸°ì¼", "ê¸ˆì•¡", "í…ìŠ¤íŠ¸", "_í•©ê³„", "_ê°­"] if col in combo_df.columns]
                    st.dataframe(combo_df[show_cols], use_container_width=True, height=400)

                    # ë‹¤ìš´ë¡œë“œ
                    csv = combo_df.to_csv(index=False).encode("utf-8-sig")
                    st.download_button("ì¡°í•© ì œì•ˆ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="match_combinations.csv", mime="text/csv")

        else:
            st.warning("ì„ ìˆ˜ê¸ˆ ê¸ˆì•¡ì´ í™•ì¸ë˜ì§€ ì•Šì•„ ì¡°í•© ì œì•ˆì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'ì „í‘œí†µí™”ì•¡' ë˜ëŠ” 'í˜„ì§€í†µí™”ì•¡'ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# -----------------------------
# âš™ï¸ ì¼ê´„ ë§¤ì¹­ ì œì•ˆ
# -----------------------------
with tab2:
    st.subheader("ì¼ê´„ ë§¤ì¹­ ì œì•ˆ(Top-1 ë‹¨ì¼ í›„ë³´)")
    max_rows = st.number_input("ëŒ€ìƒ ì„ ìˆ˜ê¸ˆ ìˆ˜(ìƒìœ„ Ní–‰)", min_value=10, max_value=min(2000, len(df_sunsu)), value=min(200, len(df_sunsu)), step=10)
    today = datetime.now()
    batch_rows = []
    # ì •ì‚°ì—¬ë¶€ê°€ ë¯¸ì •(O/Xê°€ ì•„ë‹Œ)ì¸ ê±´ ìš°ì„ 
    sunsu_order = df_sunsu.copy()
    if "ì •ì‚°ì—¬ë¶€" in sunsu_order.columns:
        sunsu_order["ë¯¸ì •ì‚°"] = ~sunsu_order["ì •ì‚°ì—¬ë¶€"].astype(str).str.contains("O", na=False)
        sunsu_order = sunsu_order.sort_values(by=["ë¯¸ì •ì‚°"], ascending=False)
    sunsu_order = sunsu_order.head(int(max_rows))

    for si, srow in sunsu_order.iterrows():
        best_score = -1.0
        best_idx = None
        for ei, erow in df_seon.iterrows():
            total, _ = calc_match_score(srow, erow, today=today, date_half_life_days=date_half_life_days)
            if total > best_score:
                best_score = total
                best_idx = ei
        if best_idx is not None and best_score >= score_threshold:
            erow = df_seon.loc[best_idx]
            batch_rows.append({
                "ì„ ìˆ˜_index": si,
                "ì„ ê¸‰_index": best_idx,
                "ì´ì ": round(best_score, 2),
                "ì„ ìˆ˜_ê³ ìœ ë„˜ë²„": srow.get("ê³ ìœ ë„˜ë²„"),
                "ì„ ìˆ˜_ê³„ì•½ë²ˆí˜¸": srow.get("ê³„ì•½ë²ˆí˜¸"),
                "ì„ ìˆ˜_ì—…ì²´ëª…": srow.get("ì—…ì²´ëª…"),
                "ì„ ìˆ˜_ì „ê¸°ì¼": srow.get("ì „ê¸°ì¼_parsed", srow.get("ì „ê¸°ì¼")),
                "ì„ ìˆ˜_ê¸ˆì•¡": srow.get("ê¸ˆì•¡"),
                "ì„ ê¸‰_ê³ ìœ ë„˜ë²„": erow.get("ê³ ìœ ë„˜ë²„"),
                "ì„ ê¸‰_ê³„ì•½ë²ˆí˜¸": erow.get("ê³„ì•½ë²ˆí˜¸"),
                "ì„ ê¸‰_ì—…ì²´ëª…": erow.get("ì—…ì²´ëª…"),
                "ì„ ê¸‰_ì „ê¸°ì¼": erow.get("ì „ê¸°ì¼_parsed", erow.get("ì „ê¸°ì¼")),
                "ì„ ê¸‰_ê¸ˆì•¡": erow.get("ê¸ˆì•¡"),
                "ì„ ê¸‰_ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸": erow.get("ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸"),
            })

    if not batch_rows:
        st.info("ì œì•ˆ ê°€ëŠ¥í•œ ë§¤ì¹­ì´ ì—†ìŠµë‹ˆë‹¤. ì ìˆ˜ ì„ê³„ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš”.")
    else:
        batch_df = pd.DataFrame(batch_rows).sort_values(by="ì´ì ", ascending=False).reset_index(drop=True)
        st.dataframe(batch_df, use_container_width=True, height=450)
        csv = batch_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ì¼ê´„ ì œì•ˆ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="batch_match_suggestions.csv", mime="text/csv")

# -----------------------------
# ğŸ“Š ëŒ€ì‹œë³´ë“œ
# -----------------------------
with tab3:
    st.subheader("ìš”ì•½ ì§€í‘œ & ì‹œê°í™”")

    # ë§¤ì¹­ ìƒíƒœ íŒŒì•…(ì •ì‚°ì—¬ë¶€, ë§í¬ë“œID ì¡´ì¬ ì—¬ë¶€ í™œìš©)
    def is_matched_row(df: pd.DataFrame) -> pd.Series:
        cond = pd.Series(False, index=df.index)
        if "ì •ì‚°ì—¬ë¶€" in df.columns:
            cond = cond | df["ì •ì‚°ì—¬ë¶€"].astype(str).str.contains("O", na=False)
        if "ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸" in df.columns:
            cond = cond | df["ì •ì‚°ì„ ìˆ˜ê¸ˆê³ ìœ ë²ˆí˜¸"].astype(str).str.strip().ne("")
        return cond

    sunsu_matched = is_matched_row(df_sunsu)
    seon_matched = is_matched_row(df_seon)

    kpi = st.columns(4)
    with kpi[0]:
        st.metric("ì„ ìˆ˜ê¸ˆ ê±´ìˆ˜", f"{len(df_sunsu):,}")
    with kpi[1]:
        st.metric("ì„ ìˆ˜ê¸ˆ ë¯¸ì •ì‚° ê±´ìˆ˜", f"{int((~sunsu_matched).sum()):,}")
    with kpi[2]:
        st.metric("ì„ ê¸‰ê¸ˆ ê±´ìˆ˜", f"{len(df_seon):,}")
    with kpi[3]:
        st.metric("ì„ ê¸‰ê¸ˆ ë¯¸ì •ì‚° ê±´ìˆ˜", f"{int((~seon_matched).sum()):,}")

    # ì—…ì²´ë³„ ë¯¸ì •ì‚° ê¸ˆì•¡ ìƒìœ„
    def group_unsettled(df: pd.DataFrame, title: str):
        base = df.copy()
        base["is_unsettled"] = ~is_matched_row(base)
        base = base[base["is_unsettled"]]
        base["ê¸ˆì•¡"] = base["ê¸ˆì•¡"].apply(to_number)
        agg = base.groupby("ì—…ì²´ëª…", dropna=False)["ê¸ˆì•¡"].sum().reset_index().sort_values(by="ê¸ˆì•¡", ascending=False).head(20)
        st.markdown(f"**{title} - ë¯¸ì •ì‚° ê¸ˆì•¡ ìƒìœ„ 20 ì—…ì²´**")
        chart = alt.Chart(agg.dropna()).mark_bar().encode(
            x=alt.X("ê¸ˆì•¡:Q", title="ê¸ˆì•¡ í•©ê³„"),
            y=alt.Y("ì—…ì²´ëª…:N", sort="-x", title="ì—…ì²´ëª…")
        ).properties(height=400)
        st.altair_chart(chart, use_container_width=True)
        st.dataframe(agg, use_container_width=True, height=300)

    c1, c2 = st.columns(2)
    with c1:
        group_unsettled(df_sunsu, "ì„ ìˆ˜ê¸ˆ")
    with c2:
        group_unsettled(df_seon, "ì„ ê¸‰ê¸ˆ")

    # ê²½ê³¼ê¸°ê°„(ê°œì›”) ë²„í‚·
    def aging_chart(df: pd.DataFrame, title: str):
        col = "ê²½ê³¼ê¸°ê°„(ê°œì›”)" if "ê²½ê³¼ê¸°ê°„(ê°œì›”)" in df.columns else None
        if col is None:
            st.info(f"{title}: 'ê²½ê³¼ê¸°ê°„(ê°œì›”)' ì»¬ëŸ¼ì´ ì—†ì–´ ì—ì´ì§• ì°¨íŠ¸ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
            return
        base = df.copy()
        base["ê¸ˆì•¡"] = base["ê¸ˆì•¡"].apply(to_number)
        base = base.dropna(subset=["ê¸ˆì•¡"])
        # ë²„í‚·íŒ…
        def bucket(x):
            try:
                v = float(x)
            except Exception:
                return "ë¯¸ìƒ"
            if v < 1: return "0-1ê°œì›”"
            if v < 3: return "1-3ê°œì›”"
            if v < 6: return "3-6ê°œì›”"
            if v < 12: return "6-12ê°œì›”"
            if v < 24: return "12-24ê°œì›”"
            return "24ê°œì›”+"
        base["ë²„í‚·"] = base[col].apply(bucket)
        agg = base.groupby("ë²„í‚·")["ê¸ˆì•¡"].sum().reset_index()
        order = ["0-1ê°œì›”", "1-3ê°œì›”", "3-6ê°œì›”", "6-12ê°œì›”", "12-24ê°œì›”", "24ê°œì›”+"]
        agg["ë²„í‚·"] = pd.Categorical(agg["ë²„í‚·"], categories=order, ordered=True)
        agg = agg.sort_values("ë²„í‚·")
        st.markdown(f"**{title} - ì—ì´ì§•(ê°œì›”) ë¶„í¬**")
        chart = alt.Chart(agg).mark_bar().encode(
            x=alt.X("ë²„í‚·:N", sort=order, title="ê²½ê³¼ê¸°ê°„ ë²„í‚·"),
            y=alt.Y("ê¸ˆì•¡:Q", title="ê¸ˆì•¡ í•©ê³„")
        ).properties(height=300)
        st.altair_chart(chart, use_container_width=True)
        st.dataframe(agg, use_container_width=True, height=250)

    c3, c4 = st.columns(2)
    with c3:
        aging_chart(df_sunsu, "ì„ ìˆ˜ê¸ˆ")
    with c4:
        aging_chart(df_seon, "ì„ ê¸‰ê¸ˆ")

    # ì›”ë³„ ì¶”ì´(ì—°ë„/ì›” í˜¹ì€ ì „ê¸°ì¼ ê¸°ì¤€)
    def monthly_trend(df: pd.DataFrame, title: str):
        base = df.copy()
        base["ê¸ˆì•¡"] = base["ê¸ˆì•¡"].apply(to_number)
        base = base.dropna(subset=["ê¸ˆì•¡"])
        if "ì—°ë„/ì›”" in base.columns:
            base["ì—°ì›”"] = base["ì—°ë„/ì›”"].astype(str)
        elif "ì „ê¸°ì¼_parsed" in base.columns:
            base["ì—°ì›”"] = base["ì „ê¸°ì¼_parsed"].dt.strftime("%Y-%m")
        else:
            return
        agg = base.groupby("ì—°ì›”")["ê¸ˆì•¡"].sum().reset_index()
        st.markdown(f"**{title} - ì›”ë³„ ê¸ˆì•¡ ì¶”ì´**")
        chart = alt.Chart(agg).mark_line(point=True).encode(
            x=alt.X("ì—°ì›”:N", sort=None, title="ì—°ì›”"),
            y=alt.Y("ê¸ˆì•¡:Q", title="ê¸ˆì•¡ í•©ê³„")
        ).properties(height=300)
        st.altair_chart(chart, use_container_width=True)
        st.dataframe(agg, use_container_width=True, height=250)

    monthly_trend(df_sunsu, "ì„ ìˆ˜ê¸ˆ")
    monthly_trend(df_seon, "ì„ ê¸‰ê¸ˆ")

st.caption("â“˜ ì ìˆ˜/ê·œì¹™/ì°¨íŠ¸ëŠ” í˜„ ë°ì´í„° êµ¬ì¡°ì— ë§ì¶° ê¸°ë³¸ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ê·œì¹™ ê°€ì¤‘ì¹˜, ì¡°í•© íƒìƒ‰ í•œë„, ì‹œíŠ¸/ì»¬ëŸ¼ëª… ë§¤í•‘ ë“±ì„ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆí•´ë“œë¦½ë‹ˆë‹¤.")
